\documentclass{systems-software}
\usepackage{float}
\usepackage{longtable}
\usepackage{tabu}
\usepackage{multirow}
\usepackage[export]{adjustbox}
\usepackage[document]{ragged2e}
\usepackage[parfill]{parskip}
\usepackage{amsmath}
\usepackage{graphicx,wrapfig,lipsum}
\usepackage{listings}

\colorlet{mygray}{black!30}
\colorlet{mygreen}{green!60!blue}
\colorlet{mymauve}{red!60!blue}

\lstset{
  backgroundcolor=\color{gray!10},  
  basicstyle=\ttfamily,
  columns=fullflexible,
  breakatwhitespace=false,      
  breaklines=true,                
  captionpos=b,                    
  commentstyle=\color{mygreen}, 
  extendedchars=true,              
  frame=single,                   
  keepspaces=true,             
  keywordstyle=\color{blue},      
  language=c++,                 
  numbers=none,                
  numbersep=5pt,                   
  numberstyle=\tiny\color{blue}, 
  rulecolor=\color{mygray},        
  showspaces=false,               
  showtabs=false,                 
  stepnumber=5,                  
  stringstyle=\color{mymauve},    
  tabsize=3,                      
  title=\lstname                
}

\begin{document}

\tsbook{COMP20081 Systems Software}
       {Revision Guide}
       {Cover Designer}
       {2017}
       {xxxxx}{xxx--xx--xxxx--xx--x}{0.0}
       {by Matt Robinson}
       {City}
       
\raggedbottom

%---------------------------------------------------------------------------
% Chapters
%---------------------------------------------------------------------------

%---------------------------------------------------------------------------
\chapter{Introduction}

\section{History of performing computations}

\section*{1950s}

A user may want to perform computations that may have a complexity that is not feasible by a standard calculator.

A description of the computations to be performed could be expressed in a physical form using a perforated card.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics{images/chapter-1/perforated-card.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Perforated card}
  \end{minipage}}
\end{figure}

There are multiple lines on the card, each with varying holes. Each line describes a particular instruction that is necessary for the computations to be completed.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    The user would describe their computations to someone who is capable of producing the correct perforated card needed for their computations.
    
	$\downarrow$
	
	The perforated card would be passed to the computer operator. A computer operator is a manager of computational resources that provides common services.
	
	$\downarrow$
	
	The computer operator would have a job queue from all of the users. These would be processed in a “first in, first out” (FIFO) fashion.
	
	$\downarrow$
	
	Jobs that are ready to be processed go in to batch processing. Each perforated card is passed through a computer system and the printed results are sent back to the user.
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Process for performing computations in the 1950s}
  \end{minipage}}
\end{figure}


\section*{$>$1960s}

The process of performing computations after 1960 changed dramatically and required far less human input.

Automation was brought about by the “Operating System Paradigm” in which users could interface with a computer system directly through an operating system (OS).

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \begin{tabular}{ccccc}
		User & $\rightarrow$ & Operating System (OS) & $\rightarrow$ & Results
	\end{tabular}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Process for performing computations after 1960}
  \end{minipage}}
\end{figure}


\section*{History details}

\begin{longtable}{|c|c|}
	\hline
	Late 1950s &
	\begin{minipage}[t]{0.8\textwidth}
    	\begin{itemize}
		    \item Standard subroutines were produced that were loaded at start-up. These contained features similar to those found on an operating system.
	  		\item Magnetic tapes were used for storage and were later replaced by disks.
	  		\item Assemblers started to be used. These are programs that takes basic computer instructions and convert them in to machine code; this is a pattern of binary bits (0’s and 1’s) that the computer system's processor can use to perform its basic operations.
	  		\item High-level languages, which consisted of more natural and human-readable language, started to be used. For example, FORTRAN is a general-purpose, compiled imperative programming language that is especially suited to numeric computation and scientific computing and was introduced in 1957.
    	\end{itemize}
  	\end{minipage}
	\\ \hline
	1960s &
	\begin{minipage}[t]{0.8\textwidth}
	  	Automated batch system.
	    \begin{itemize}
		    \item This replaced the computer operator.
		    \item Several programs could be loaded in to memory and automatically processed in a “first in, first out” (FIFO) fashion.
    	\end{itemize}
	\end{minipage}
	\\ \hline
	1970s &
	\begin{minipage}[t]{0.8\textwidth}
	  	Multiprogramming.
	    \begin{itemize}
		    \item The computer could switch between jobs, which allows processing and input/output (I/O) interaction simultaneously.
    	\end{itemize}
	\end{minipage}
	\\ \hline
	1980s &
	\begin{minipage}[t]{0.8\textwidth}
	  	Graphical user interfaces (GUIs).
	    \begin{itemize}
		    \item The interaction between a computer system and a user through the medium of a mouse and keyboard.
    	\end{itemize}
	\end{minipage}
	\\ \hline
\end{longtable}


\section{Hardware}

\section*{External hardware}

A \textbf{peripheral} is any external hardware device that provides input/output (I/O) for the computer.

For example, a keyboard and mouse are input peripherals, while a monitor and printer are output peripherals. Some peripherals, such as external hard drives, provide both input and output for the computer.

A computer system generally has many internal hardware components and hardware peripherals.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-1/external-view-of-computer-system.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{External view of computer system}
  \end{minipage}}
\end{figure}

\section*{Internal hardware}

A \textbf{processor} or \textbf{central processing unit (CPU)} is the hardware within a computer that carries out the instructions of a computer program by performing the basic arithmetical, logical, and input/output operations of the system.

A \textbf{motherboard} is the main printed circuit board (PCB) in a computer. The motherboard is a computer's central communications backbone connectivity point, through which all components and external peripherals connect.

Inside of a computer system, there are many components connected to the processor via the motherboard.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-1/typical-computer-motherboard.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Typical computer motherboard}
  \end{minipage}}
\end{figure}

The motherboard connects:
\begin{itemize}
	\item all of the internal components via the data bus; and
	\item the peripherals.
\end{itemize}


\section{What is an operating system (OS)?}

\section*{Definition}

An \textbf{operating system (OS)} is a collection of system programs that manage the hardware resources and peripherals connected to a computer system. It is also responsible for the graphical user interface or command line interface and all other software running on the computer system.


\section*{Purpose of an operating system (OS)}

An operating system (OS) is designed to:
\begin{itemize}
	\item eliminate the need to have hardware knowledge to operate a computer system;
	\item make the boundary between hardware and software transparent, allowing the user to not be concerned with the technical details; and
	\item provide a user-friendly environment to execute and develop programs.
\end{itemize}

These attributes are achieved by layering the computer system such that the user can interface with applications, rather than the operating system (OS) or the hardware directly.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    User
    
	$\updownarrow$
	
	Applications
	
	$\updownarrow$
	
	Operating System (OS)
	
	$\updownarrow$
	
	Computer System Hardware
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Computer system layers}
  \end{minipage}}
\end{figure}


\section*{Structure of an operating system (OS)}

The structure of an operating system (OS) can be said to resemble an onion.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-1/structure-of-an-os.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Structure of an operating system (OS)}
  \end{minipage}}
\end{figure}

An operating system (OS) has four main components.

The \textbf{kernel} hides the complexity of how a computer system works from users. It is responsible for:
\begin{itemize}
	\item process management;
	\item CPU scheduling; and
	\item handling interrupts.
\end{itemize}
\textbf{Memory management} is responsible for allocating and deallocating memory to processes.

\textbf{Input/output (I/O)} includes any interaction between the internal computer system components and peripherals.

The \textbf{filing system} is comprised of file management subsystems.

Each layer in the operating system (OS) structure provides functions to the above layers. Each layer uses facilities provided by layers within and below that layer. 


\section*{Practical features of current operating systems (OSs)}

\begin{longtable}{|c|c|}
	\hline
	Concurrency &
	\begin{minipage}[t]{0.6\textwidth}
	Allows overlapping input/output (I/O) operations with computations and several programs to be stored in memory at a single time.
	\end{minipage}
	\\ \hline
	Sharing of resources &
	\begin{minipage}[t]{0.6\textwidth}
	Sharing hardware and peripherals, such as hard disks and printers.
	\end{minipage}
	\\ \hline
	Access to long term storage &
	\begin{minipage}[t]{0.6\textwidth}
	Important for saving important files on mediums such as hard disk drives (HDDs) and solid-state drives (SSDs).
	\end{minipage}
	\\ \hline
	Non-determinacy &
	\begin{minipage}[t]{0.6\textwidth}
	The ability to cope with unpredictable events without crashing.
	\end{minipage}
	\\ \hline
\end{longtable}


\section{Functions of an operating system}

An operating system (OS) has two main complementary functions:
\begin{itemize}
	\item resource managing; and
	\item machine extending.
\end{itemize}


\section*{Resource managing}

It manages resources shared among users and user programs and maximises their utilisation of the CPU, RAM and other resources. This is done simultaneously in order to increase the availability.

This is similar to the role of computer operators in the 1950s.


\section*{Machine extending}

It presents a virtual machine (or extended machine) to users that is much easier to access than the underlying physical machine.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-1/machine-extending.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Machine extending}
  \end{minipage}}
\end{figure}

The virtual machine presented to the user provides an abstraction of the computer system. This hides the complexity of the hardware from the user; this means that the user need only be concerned with the details of the hardware if they desire.

This is a way of translating the functions needed by a user from the hardware to a presentable and user-friendly medium. As a result, the operating system (OS) acts as an intermediary layer between the user and machine language.

The benefit of this abstraction can be demonstrated when comparing how computations may be processed with and without an operating system (OS).

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtable}{|c|c|}
    	\hline
		\textbf{Without Operating System (OS)} & \textbf{With Operating System (OS)} \\
		\hline
		\begin{minipage}[t]{0.45\textwidth}
	    	The instructions written in machine code or assembly language much interface directly with memory hardware. As such, the memory locations to load the two numbers from must be explicitly defined and the memory location to which the result is stored must also be defined.
	    	
			The example below shows a possible assembly code implementation of a computation that is capable of adding two numbers.
	  	\end{minipage}
		&
		\begin{minipage}[t]{0.45\textwidth}
	    	The instructions can be written in a high-level language, such as C++.
	  	\end{minipage}
		\\ \hline
		\begin{minipage}[t]{0.45\textwidth}
			\begin{tabular}{p{2cm} | p{3.5cm}}
				\hline
				LDAA \$80 & (load number at memory location 80) \\
				\hline
				LDAB \$81 & (load number at memory location 81) \\
				\hline
				ADDB & (add these two numbers) \\
				\hline
				STAA \&55 & (store the sum to memory location 55) \\
				\hline
			\end{tabular}
	  	\end{minipage}
		&
		\begin{minipage}[t]{0.45\textwidth}
	    	int a, b, c;
	    	
			a = 1;
			
			b = 2;
						c = a + b;
	  	\end{minipage}
	\end{longtable}
	
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Adding two numbers}
  \end{minipage}}
\end{figure}

This demonstrates that program development is much more user-friendly with an operating system (OS). This is because without an operating system (OS) the user must have knowledge of the system hardware; in this case, the necessary memory locations.

In addition, it is possible that the machine code or assembly language written may not work on another computer system as that computer system may have a different architecture or the memory locations may be different. For example, in another computer system:
\begin{itemize}
	\item memory location 81 may not exist as the memory is smaller; or
	\item memory location 55 contains important data or instructions that should not be overwritten and therefore the computer system may crash.
\end{itemize}

By contrast, with an operating system (OS), it is possible to perform computations without interfacing directly with hardware. In the example above, variables (a, b and c) can be used to access data in memory rather than addressing memory locations. The only concern here is that the variable c is able to store the result of a + b.

The operating system (OS) provides a unified environment to users to run their computations in different systems. The operating system (OS) is capable of taking high-level code and translating it in to the machine code that can be executed on a particular computer system.

\section{Current operating system (OS) trends}

\section*{Hardware evolution}

Due to fast rate of hardware evolution, operating systems (OSs) are more wide-spread than just traditional desktop computers. They can be found on hardware such as:
\begin{itemize}
	\item mobile devices, such as smartphones and tablets; and
	\item embedded systems.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtable}{|c|c|c|}
    	\hline
		\textbf{Desktop} & \textbf{Mobile} & \textbf{Embedded} \\
		\hline
		\begin{minipage}[t]{0.26\textwidth}
	    	\begin{itemize}
	    		\item Windows
	    		\item macOS
	    		\item Linux
	    	\end{itemize}
	  	\end{minipage}
		&
		\begin{minipage}[t]{0.26\textwidth}
	    	\begin{itemize}
	    		\item iOS
	    		\item Android
	    		\item Symbian OS
	    	\end{itemize}
	  	\end{minipage}
		&
		\begin{minipage}[t]{0.26\textwidth}
	    	\begin{itemize}
	    		\item Windows Embedded
	    	\end{itemize}
	  	\end{minipage}
	  	\\ \hline
	\end{longtable}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Popular operating systems (OSs)}
  \end{minipage}}
\end{figure}


\section*{Multiprocessor systems}

\subsection*{Definiton}

A \textbf{multiple processor computer system} makes use of two or more processors and has the ability to allocate tasks between them.


\subsection*{Workstations}

A single machine may contain multiple processors and therefore have large computing power.


\subsection*{Distributed and network systems}

These computer systems share computing power and peripherals.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-1/distributed-and-network-systems.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Distributed and network systems}
  \end{minipage}}
\end{figure}

The diagram shows an abstraction of a distributed or network system. P1 and P2 are the connected computer systems that both share memory, access to the disk control and, if the system is a network system, the network interface.

However, there is a distinguishable difference between distributed and network systems.

\begin{longtable}{|c|c|}
	\hline
	\textbf{Similarities} & \textbf{Differences} \\
	\hline
	\begin{minipage}[t]{0.45\textwidth}
		Consist of multiple systems that are interconnected to exchange information.
	\end{minipage}
	&
	\begin{minipage}[t]{0.45\textwidth}
		In distributed systems, users are not aware of the multiplicity of computer systems available.
	\end{minipage}
	\\ \hline
	&
	\begin{minipage}[t]{0.45\textwidth}
		In network systems, users explicitly move/share files, submit jobs for processing and other perform other similar tasks.
	\end{minipage}
	\\ \hline
	&
	\begin{minipage}[t]{0.45\textwidth}
		In distributed systems, tasks such as moving/sharing files, submitting jobs for processing and other similar tasks are handled automatically by the operating system (OS).
	\end{minipage}
	\\ \hline
\end{longtable}


\subsection*{Evaluation}

\begin{longtable}{|c|c|}
	\hline
	\textbf{Advantages} & \textbf{Disadvantages} \\
	\hline
	\begin{minipage}[t]{0.45\textwidth}
		\textbf{Increase processor throughput} due to the use of parallel processing.
	\end{minipage}
	&
	\begin{minipage}[t]{0.45\textwidth}
		\textbf{A more complex operating system is required} in order to be able to interface and manage multiple processor units.
	\end{minipage}
	\\ \hline
	\begin{minipage}[t]{0.45\textwidth}
		\textbf{Lower cost} than using multiple processors across multiple computer systems because the processors share resources such as the power supply and motherboard.
	\end{minipage}
	&
	\\ \hline
	\begin{minipage}[t]{0.45\textwidth}
		\textbf{Increased reliability} because failure of one processor does not affect the other processors and will only slow down the computer system.
	\end{minipage}
	&
	\\ \hline
\end{longtable}


\section{Operating system (OS) layers}

\section*{User interfaces}

In an operating system (OS), the top layer is the user interface. This is the only layer explicitly visible to the user.

The user interface may be a:
\begin{longtabu} to \textwidth {X[6,l] X[1,c] X[10,l]}
	\textbullet terminal & -- & text-based command prompt; and/or
	\\
	\textbullet graphical user interface (GUI) & -- & a visual way of interacting with a computer using items such as windows, icons and menus.
\end{longtabu}


\subsection*{History of the graphical user interface (GUI)}

The first company to develop a graphical user interface (GUI) was Xerox PARC. They developed the “Alto” personal computer. It had a bitmapped screen and was the first computer to have a “desktop” screen with a graphical user interface (GUI).

The “Alto” personal computer was not a commercial product. However, several thousand units were manufactured and used at Xerox’s offices and several universities.

This development was a large influence on the design of personal computers during the late 1970s and early 1980s. Notable examples include:
\begin{itemize}
	\item Three Rivers PERQ;
	\item Apple Lisa;
	\item Apple Macintosh; and
	\item the first Sun Workstations.
\end{itemize}


\section{Kernel mode}

\section*{Kernel mode vs user mode}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Kernel Mode} & \textbf{User Mode}
    \\ \hline
    Operating systems (OSs) run in kernel mode.
    
    This allows:
    \begin{itemize}
    	\item execution of privileged machine instructions; and
    	\item complete access and control of all the hardware.
    \end{itemize}
    &
    Other software runs in user mode.

	In this mode, instructions that affect control of the machine are forbidden.

	For example:
	\begin{itemize}
		\item 	web browsers;
		\item e-mail software; and
		\item music players.
	\end{itemize}
	\\ \hline
\end{longtabu}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-1/kernel-mode-and-user-mode.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Kernel mode and user mode}
  \end{minipage}}
\end{figure}

Ring 0 represents the kernel mode.

Rings 1-3 represent the user mode.


\section*{Kernel mode protection}

These rings allow separation between the operating system (OS) and user programs for security and protection purposes.

If user mode had unrestricted access to all of the machine instructions:
\begin{itemize}
	\item a user could inadvertently obtain a virus or write code that is capable of causing damage to the system, and therefore it is necessary to prevent any instructions from directly controlling the machine;
	\item a program may use resources unfairly, such as holding the CPU or memory, and therefore harm the execution of other programs; and/or
	\item sensitive machine instructions could be used improperly which may lead to kernel mode errors.
\end{itemize}
Kernel mode errors are catastrophic.


\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
	    \hline
	    \textbf{Kernel Mode} & \textbf{User Mode}
	    \\ \hline
	    A kernel panic represents the operating system (OS) attempting to prevent software causing any harm to the computer system and to recover from a kernel mode error on reboot.
	    
	    An example of a kernel panic is the “Blue Screen of Death” (BSoD) in Microsoft’s Windows.
	    &
	    Application errors where an exception was thrown due to an attempt to execute a privileged instruction, this is one that should only be accessed and executed by the kernel mode, represents the operating system (OS) preventing an application from having unrestricted access to all of the machine instructions.
		\\ \hline
		\centering
    	\includegraphics[max size={0.45\textwidth}{\textheight}]{images/chapter-1/kernel-mode-error-bsod.png}
	    &
	    \centering
    	\includegraphics[max size={0.45\textwidth}{\textheight}]{images/chapter-1/kernel-mode-error-application-error.png}
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Kernel mode errors}
  \end{minipage}}
\end{figure}


\section*{System calls}

A \textbf{system call} is the programmatic way in which a computer program requests a service from the kernel of the operating system on which it is executed. A system call is a way for programs to interact with the operating system.

Some privileged instructions can be called by a programmer via system calls. Operating systems (OSs) contain system calls for which provide a layer of services for user programs to implement some activities/request services. These are usually sensitive or privileged from the kernel.

All interactions with the hardware are implemented via system calls. For example, a system call may occur if an application requires interaction with a peripheral such as a printer.

Invoking a system call is similar to calling a general function. However, the difference is that a general function’s code is part of program itself, while the system call code is part of the operating system (OS). Different operating systems (OSs) offer different (limited) sets of system calls.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {| X[1,l] | X[2,l] |}
	    \hline
	    \textbf{Call} & \textbf{Description}
	    \\ \hline
	    \multicolumn{2}{|c|}{\textbf{Process Mangament}}
	    \\ \hline
	    pid = fork()
	    &
	    Create a child process identical to the parent.
		\\ \hline
		exit(status)
	    &
	    Terminate process execution and return status.
		\\ \hline
		\multicolumn{2}{|c|}{\textbf{File Mangament}}
	    \\ \hline
	    n = read(fd, buffer, nbytes)
	    &
	    Read data from a file in to a buffer.
		\\ \hline
		n = write(fd, buffer, nbytes)
	    &
	    Write data to a file
		\\ \hline
		\multicolumn{2}{|c|}{\textbf{Process Mangament}}
	    \\ \hline
	    seconds = time(\&seconds)
	    &
	    Get the elapsed time since Jan 1. 1970
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Unix system calls}
  \end{minipage}}
\end{figure}


\chapter{Process Management}

\section{Programs and processes}

\section*{Definitions}

A \textbf{program} is the code written by a programmer.

A \textbf{process} (or job/task) shows a program in execution and is a particular instance of a program. These many be shown in a monitoring software, such as Windows Task Manager.

\textbf{Data} are stored values used for the computations by the process.


\section*{How it works}

A single program may have multiple processes that are currently running.

Each process can share the same code for the program. This is possible as each process uses its own address space, a list of memory locations which the process can read and write. These memory locations contain the program’s code instructions and data.

A program is only code however, once it is run, a process is started, and it becomes instructions and data.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/programs-and-processes.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Programs and processes}
  \end{minipage}}
\end{figure}


\section{Process life cycle}

\section*{Process creation}

A process can be created by:

\begin{longtabu} to \textwidth {X[3,l] X[1,c] X[10,l]}
	\textbullet a user & -- & a program may be executed by a user, such as via a double-click using a graphical user interface (GUI) or by typing in a command, and “trigger” the processor to load the program’s executable file containing the program code; or
	\\
	\textbullet another process & -- & an existing process may create another process by spawning/forking – the process that creates a new process is called the parent process while the new process is called the child process. The child process may also spawn a new process forming a tree of processes, as demonstrated in the diagram below.
\end{longtabu}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/process-creation.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Process creation}
  \end{minipage}}
\end{figure}


\section*{Process table and process control block}

A \textbf{process identification number (PID)} is a unique identifier given to a new process when it is created.

A \textbf{process control block (PCB)} holds all of the information about a process. It is created when new process is created.

A \textbf{process table} stores the process identification numbers (PIDs) for a process and a pointer to the respective process control block (PCB) for that process. This is managed by the operating system (OS).

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/process-table.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Process table with respective process control blocks}
  \end{minipage}}
\end{figure}

The process descriptor fields in the process control block (PCB) may differ between operating system (OS). An example of possible process descriptor fields is shown by those used by the Minix operating system (OS) are shown below.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {X[2,l] X[2,l] X[2,l]}
	    \hline
	    \textbf{Process Management} & \textbf{Memory Management} & \textbf{File Management}
	    \\ \hline
	    Registers & Pointer to text segment	& UMASK mask
		\\ \hline
		Program counter & Pointer to data segment & Root directory
		\\ \hline
		Program status word & Pointer to bss segment & Working directory
		\\ \hline
		Stack pointer & Exit status & File descriptors
		\\ \hline
		Process state & Signal status & Effective uid
		\\ \hline
		Time when process started & Process ID & Effective gid
		\\ \hline
		CPU time used & Parent process & System call parameters
		\\ \hline
		Children’s CPU time & Process group & Various flag bits
		\\ \hline
		Time of next alarm & Real uid &
		\\ \hline
		Message queue pointers & Effective uid &
		\\ \hline
		Pending signal bits & Real gid &
		\\ \hline
		Process ID & Effective gid &
		\\ \hline
		Various flag bits & Various flag bits &
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Process descriptor fields in Minix}
  \end{minipage}}
\end{figure}

Although Minix is a fully-featured operating system (OS), it is a small operating system (OS) and therefore the processor descriptor fields are less complex than other operating systems (OSs).


\section*{Three-state model}

The \textbf{three-state model} shows how a process, once initiated, can be in one of three states. The current state of a process is stored in its respective process control block (PCB).

A process, once initiated, can be in one of three main states:
\begin{longtabu} to \textwidth {X[2,l] X[1,c] X[10,l]}
	\textbullet running & -- & actually using the CPU to perform a task;
	\\
	\textbullet ready & -- & ready to run but waiting for the CPU as it has not yet had time on the CPU has been temporarily stopped to let another process run; or
	\\
	\textbullet ready & -- & unable to run until some external event occurs, such as:
		\begin{itemize}
			\item waiting for an interrupt, this is a message from the hardware saying that a resource is now available to read from – such as waiting for an input/output (I/O) operation to complete; and
			\item waiting for another process to finish accessing a shared resources – for example: a file; memory; or an external peripheral, such as a printer.
		\end{itemize}
\end{longtabu}
\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/process-states.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Process states}
  \end{minipage}}
\end{figure}

In reference to the diagram above, transitions can occur between process states.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {|X[4,l]|X[1.5,l]|X[6,l]|}
	    \hline
	    \textbf{Transition} & \textbf{Diagram Number} & \textbf{Explanation}
	    \\ \hline
	    \textbf{running $\rightarrow$ blocked}
	    & \textbf{1} &
	    \textbf{Process blocks for input.}
	    
		For example, if the process is waiting for some input from I/O.
		\\ \hline
		\textbf{running $\rightarrow$ ready}
	    & \textbf{2} &
	    \textbf{Scheduler picks another process.}
	    
		The process has had opportunity to run and is flagged as no longer currently running, so that another process can run.
		\\ \hline
		\textbf{ready $\rightarrow$ running}
	    & \textbf{3} &
	    \textbf{Scheduler picks this process.}
		The next process that is ready to run is set to running to allow access to the CPU.
		\\ \hline
		\textbf{blocked $\rightarrow$ ready}
	    & \textbf{4} &
	    \textbf{Input becomes available.}
		The process has received input from I/O or the process sends an interrupt and the interrupt service routine (ISR) is executed, the scheduler is called to transition the process from blocked to ready.
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Transitions between processor states}
  \end{minipage}}
\end{figure}

The transition between process states is dependent on the scheduling algorithm used. A clock is used to send a signal to stop the current process, move it from running to ready and then run the scheduler to find out what process should be processed next and the next process will be made to running.


\section*{State queues}

At any time, a process is in only one state.


\subsection*{Running processes}

At any time, at most one process is in the running state. This is because a single-core processor is only able to process one instruction coming from a single core at a time. If a computer system has a multi-core processor, this rule applies to each individual core on the processor, rather than the processor as a whole, as they are able to complete parallel execution.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/running-processes.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Running processes}
  \end{minipage}}
\end{figure}


\subsection*{Ready processes}

There may be a queue of processes in the ready state.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/ready-processes.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Ready processes}
  \end{minipage}}
\end{figure}


\subsection*{Blocked processes}

There may be several queues of processes in the blocked state, where each queue represents one resource for which processes in that queue are waiting.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/currently-running-processes.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Currently running processes}
  \end{minipage}}
\end{figure}


\section*{Process termination}

\textbf{Process termination} is the end of life for a process, this can occur in two general ways.


\subsection*{Voluntary termination}

\textbf{Voluntary termination} of a process represents the end of life for a process where its termination was intended by the user or the programmer.

This can be a:
\begin{longtabu} to \textwidth { X[1.5,l] X[0.2,l] X[7,l]}
	\textbf{\textbullet normal exit}
	& -- &
	the process has done its work; or
	\\
	\textbf{\textbullet error exit}
	& -- &
	the process itself handles and “catches” an error – for example, some try-catch code is implemented to check if a condition is met, such as if the definition of a variable is present.
\end{longtabu}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/voluntary-termination.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Voluntary termination due to an error exit}
  \end{minipage}}
\end{figure}


\subsection*{Involuntary termination}

\textbf{Involuntary termination} of a process represents the end of life for a process where its termination as not intended by the user or the programmer.

This can be due to:
\begin{longtabu} to \textwidth { X[1.5,l] X[0.2,l] X[7,l]}
	\textbf{\textbullet a fatal error}
	& -- &
	an error is detected by the operating system’s (OS’s) protected mode – for example, an exception has been thrown due to reference to a non-existent memory location or division by zero; or
	\\
	\textbf{\textbullet being killed by another process}
	& -- &
	a process may execute a system call that causes the operating system (OS) to kill another process – this process may have control over the killed process and this may be due to that process being the parent process of the killed process.
\end{longtabu}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/involuntary-termination.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Voluntary termination due to an error exit}
  \end{minipage}}
\end{figure}


\newpage
\section{Program execution}

\section*{The simple fetch-execute cycle}

\subsection*{Definition}

The \textbf{fetch-execute cycle} is an operational process in which a computer system retrieves a program instruction from its memory, determines what actions the instruction dictates, and carries out those actions.


\subsection*{How it works}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/simple-fetch-execute-cycle.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Simple fetch-execute cycle}
  \end{minipage}}
\end{figure}

Once a process is started, instructions are fetched from memory and executed using the CPU. This process will continue until the process is terminated.

This predictable cycle is only feasible to an extent as some processes may be slow or blocked and other may require immediate attention and cannot wait for the current process to terminate. For example, if a process blocks the processor (CPU) because it is waiting for an event to occur, such as a printer to finish its job, or if a high-priority process is supposed to execute as soon as possible. In these cases, interrupts are required.


\section*{Interrupts}

\subsection*{Definition}

An \textbf{interrupt} is a signal sent to the processor indicating that an event caused by hardware or software requires immediate attention.


\subsection*{Types of interrupts}

\begin{longtabu} to \textwidth { X[1.5,l] X[0.2,l] X[7,l]}
	\textbf{\textbullet Input/output (I/O) interrupt}
	& -- &
	Caused by an input/output (I/O) device to signal completion or an error.
	\\
	\\
	\textbf{\textbullet Timer interrupt}
	& -- &
	Caused by a processor timer and is used to alert the operating system (OS) at specific instants.
	\\
	\\
	\textbf{\textbullet Program interrupt}
	& -- &
	Caused by error conditions within user programs or fatal errors.
\end{longtabu}


\subsection*{When do interrupts occur?}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/interrupt-graph.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
	A process requiring immediate attention is waiting for the processor (CPU).	
	For example, an input/output (I/O) event occurs.	
	$\downarrow$
	
	The currently running process’ execution is suspended.
	
	$\downarrow$
	
	Processor switches execution to another process.
	
	$\downarrow$
	
	When input/output (I/O) completes, an interrupt will occur.
	
	$\downarrow$
	
	The execution is diverted to the interrupt handling routine.	
	An interrupt handling routine (ISR) contains the operations that are performed to deal with an interrupt. Different types of interrupts can have different routines.
	
	$\downarrow$
	
	The suspended program may restart, if conditions are met.
	\end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Interrupt occurring due to input/output (I/O) event}
  \end{minipage}}
\end{figure}

Interrupts enable operating systems (OSs) to oversee several programs and input/output (I/O) events simultaneously.

This also means that single-core processors can effectively emulate the way in which multi-core processors deal with multiple instructions at a given time by switching between instructions intelligently. Due to the high clock speeds of modern processors, it is easy to give the illusion that true multi-tasking, where two instructions are being processed at once, is taking place on a single-core processor.


\subsection*{Updated fetch-execute cycle}

Given the introduction of interrupts, it is now necessary to update the fetch-execute cycle in order to include the possibility of an interrupt.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/updated-fetch-execute-cycle.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Updated fetch-execute cycle}
  \end{minipage}}
\end{figure}


\section{Concurrency}

\section*{Definition}

\textbf{Concurrency} describes the ability for a program to be decomposed in to parts that can run independently of each other. This means that tasks can be executed out of order and the result would still be the same as if they are executed in order.


\section*{Why is concurrency required}

Concurrency allows the processor (CPU) to run several processes. An example of this is shown by an interrupt occurring due to an input/output (I/O) event occurring (page 24).


\section*{Interleaving}

Concurrency is able to achieve multitasking, that does not require parallel execution, by performing interleaved execution.


\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.4935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/interleaving-program-counters.png}
  \end{minipage}
  \begin{minipage}{0.5\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/interleaving-graph.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Interleaving}
  \end{minipage}}
\end{figure}


\section{Process scheduling}

\section*{The scheduler}

\subsection*{Definition}

A \textbf{scheduler} uses a scheduling algorithm to determine how to share processor time.


\subsection*{How it works}

After an input/output (I/O) system call or interrupt handling, control is passed to the scheduler to decide which process to execute next.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/the-scheduler.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{The scheduler}
  \end{minipage}}
\end{figure}

The scheduler checks if the current process is still the most suitable to run at this moment in time. If it is control is returned to the process, otherwise:
\begin{itemize}
	\item the state of the current process is saved in the process control block (PCB);
	\item the state of the most suitable process is retrieved from the process control block (PCB); and
	\item control is transferred to the newly selected process at the point indicated by the restored program counter (PC).
\end{itemize}

The action of storing the state of the current process and activating another process is called a context switch.

Context switching must be minimised to reduce overheads created by copying the state of processed and the time taken to perform the switch. However, it is still regarded as important to context switch when appropriate to avoid longer waiting times in the event of a blocked process.


\section*{Scheduling}

\subsection*{Definition}

\textbf{Scheduling} is the act of determining the optimal sequence and timing of assigning execution to processes.


\subsection*{Scheduling criteria}

Different scheduling criteria may be selected depending on the use case for a given computer system.

\begin{longtabu} to \textwidth { X[1.5,l] X[0.2,l] X[7,l]}
	\textbf{\textbullet CPU utilisation}
	& -- &
	Aims to keep the CPU as busy as possible.
	\\
	\\
	\textbf{\textbullet Efficiency}
	& -- &
	Aims to maximise system throughput.
	\\
	\\
	\textbf{\textbullet Fairness}
	& -- &
	Aims to be fair to all running processes or to all users on a multi-user operating system (OS).
\end{longtabu}

This means that different policies and algorithms for scheduling will exist to match these criteria.


\section*{Scheduling policies}

A \textbf{non-preemptive scheduling policy} is one that allows processes to run until complete or incurring an input/output (I/O) wait. These scheduling policies can be described as passive.

A \textbf{preemptive scheduling policy} is one that allows processes to be interrupted and replaced by other processes, generally through timer interrupts.


\section*{Scheduling algorithms}

\subsection*{Definitions}

\textbf{Arrival time} is the instant at which a process is first created.

\textbf{Service time} is the time that it takes for a process to complete if it is in continuous execution.

The \textbf{waiting time} for a process is the sum of time spent in the ready queue during the life of the process. This does not include time that the process is blocked or waiting for input/output (I/O).

In order for a scheduling algorithm to be deemed as fair to all processes, the ratio between waiting time and run time should be about the same for each process.


\subsection*{Case study}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {|X[1,c]|X[1,c]|X[1,c]|}
	    \hline
	    \textbf{Process} & \textbf{Arrival Time} & \textbf{Service Time}
	    \\ \hline
	    A & 0 & 3
	    \\ \hline
	    B & 2 & 6
	    \\ \hline
	    C & 4 & 4
	    \\ \hline
	    D & 6 & 5
	    \\ \hline
	    E & 8 & 2
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Case study}
  \end{minipage}}
\end{figure}

The case study shows different processes (A-E) that all have different arrival times and different service times.

The following examples of scheduling algorithms will refer to this case study to demonstrate their function.


\subsection*{First come, first served (FCFS) / First in, first out (FIFO) – Non-preemptive}

In this algorithm, the first process to arrive is assigned to the processor (CPU) until it is finished. Meanwhile, any other processes that come along are queued up waiting to be processed.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.2935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\begin{longtabu} to \textwidth {|X[1,c]|X[1,c]|X[1,c]|}
	    \hline
	    \textbf{Process} & \textbf{Arrival Time} & \textbf{Service Time}
	    \\ \hline
	    A & 0 & 3
	    \\ \hline
	    B & 2 & 6
	    \\ \hline
	    C & 4 & 4
	    \\ \hline
	    D & 6 & 5
	    \\ \hline
	    E & 8 & 2
		\\ \hline
	\end{longtabu}
  \end{minipage}
  \begin{minipage}{0.7\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/temporal-diagram-fcfs.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Temporal diagram for FCFS / FIFO}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Simple to implement}.
    &
    \textbf{Does not consider the priority of a process} and therefore the important processes may not be completed quickly.
    \\ \hline
    &
    \textbf{Prevents other processes from starting} while another is in progress and therefore, if processes are of varying sizes, there may be inefficiencies since a single process may take a long time to complete therefore leaving the user waiting before they can perform any other actions.
	\\ \hline
	\multicolumn{2}{|p{\textwidth}|}{\textbf{Favours long processes} as all processes are given the opportunity to run until completion and therefore, some shorter processes may not be able to start processing until the longer processes are finished.}
	\\ \hline
\end{longtabu}
	

\subsection*{Shortest job first (SJF) – Non-preemptive}

In this algorithm, the process with the shortest estimated run time is assigned to the processor (CPU) until it is finished. Meanwhile, any other processes that come along are queued up waiting to be processed.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.2935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\begin{longtabu} to \textwidth {|X[1,c]|X[1,c]|X[1,c]|}
	    \hline
	    \textbf{Process} & \textbf{Arrival Time} & \textbf{Service Time}
	    \\ \hline
	    A & 0 & 3
	    \\ \hline
	    B & 2 & 6
	    \\ \hline
	    C & 4 & 4
	    \\ \hline
	    D & 6 & 5
	    \\ \hline
	    E & 8 & 2
		\\ \hline
	\end{longtabu}
  \end{minipage}
  \begin{minipage}{0.7\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/temporal-diagram-sjf.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Temporal diagram for SJF}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Simple to implement}.
    &
    \textbf{Does not consider the priority of a process} and therefore the important processes may not be completed quickly.
    \\ \hline
  	\textbf{Shorter processes are processed quickly} because they take precedence.
    &
    \textbf{Relies on an estimation} of how long a process will take which could be incorrect.
    \\ \hline
  	\textbf{Minimises the average time taken to complete a process} because the shortest processes take precedence.
    &
    \textbf{Prevents other processes from starting} while another is in progress and therefore, if processes are of varying sizes, there may be inefficiencies since a single process may take a long time to complete therefore leaving the user waiting before they can perform any other actions.
	\\ \hline
	\multicolumn{2}{|p{\textwidth}|}{\textbf{Favours long processes} as the processes with the shortest estimated time are given the opportunity to run until completion and therefore, some longer processes may not be able to start processing until there are no more shorter processes currently running or ready to be processed.}
	\\ \hline
\end{longtabu}


\subsection*{Shortest remaining time (SRT) – Preemptive}

In this algorithm, the process with the shortest estimated remaining time is assigned to the processor (CPU). If a process becomes ready that has a shorter remaining time, it will be pre-empted to allow the new process to start and the scheduler is switched to that new process.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.2935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\begin{longtabu} to \textwidth {|X[1,c]|X[1,c]|X[1,c]|}
	    \hline
	    \textbf{Process} & \textbf{Arrival Time} & \textbf{Service Time}
	    \\ \hline
	    A & 0 & 3
	    \\ \hline
	    B & 2 & 6
	    \\ \hline
	    C & 4 & 4
	    \\ \hline
	    D & 6 & 5
	    \\ \hline
	    E & 8 & 2
		\\ \hline
	\end{longtabu}
  \end{minipage}
  \begin{minipage}{0.7\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/temporal-diagram-srt.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Temporal diagram for SRT}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{High throughput} because the number of processes completed is high due to the shortest processes taking precedence.
    &
    \textbf{Does not consider the priority of a process} and therefore the important processes may not be completed quickly.
    \\ \hline
  	\textbf{Shorter processes are processed quickly} because they take precedence.
    &
    \textbf{Relies on an estimation} of how long a process will take which could be incorrect.
    \\ \hline
  	
    &
    \textbf{Can be inefficient} if a large process is in progress and shorter processes are being added to the queue because they will take precedence.
	\\ \hline
	\multicolumn{2}{|p{\textwidth}|}{\textbf{Favours long processes} as the processes with the shortest estimated time are given the opportunity to run until a process with a shorter estimated time is ready and therefore, some longer processes may not be able to start processing until there are no more shorter processes currently running or ready to be processed.}
	\\ \hline
\end{longtabu}


\subsection*{Highest response ratio next (HRRN) – Preemptive}

In this algorithm, the process with the highest priority is assigned to the processor (CPU). If a process becomes ready that has a higher priority, it will be pre-empted to allow the new process to start and the scheduler is switched to that new process.

The priority of a process may be based on memory, time and/or any other resource requirement such as:
\[\frac{waiting time + run time}{run time}\]

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.2935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\begin{longtabu} to \textwidth {|X[1,c]|X[1,c]|X[1,c]|}
	    \hline
	    \textbf{Process} & \textbf{Arrival Time} & \textbf{Service Time}
	    \\ \hline
	    A & 0 & 3
	    \\ \hline
	    B & 2 & 6
	    \\ \hline
	    C & 4 & 4
	    \\ \hline
	    D & 6 & 5
	    \\ \hline
	    E & 8 & 2
		\\ \hline
	\end{longtabu}
  \end{minipage}
  \begin{minipage}{0.7\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/temporal-diagram-hrrn.png}
  	This diagram assumes that the processes are assigned a letter in reverse order of priority, such that E has the greatest priority and A has the lowest priority.
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Temporal diagram for HRRN}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{High throughput} because the number of processes completed is high due to the shortest processes taking precedence.
    &
    \textbf{Does not consider the priority of a process} and therefore the important processes may not be completed quickly.
    \\ \hline
  	\textbf{Shorter processes are processed quickly} because they take precedence.
    &
    \textbf{Relies on an estimation} of how long a process will take which could be incorrect.
    \\ \hline
  	
    &
    \textbf{Can be inefficient} if a large process is in progress and shorter processes are being added to the queue because they will take precedence.
	\\ \hline
\end{longtabu}


\subsection*{Round robin (RR) – Preemptive}

In this algorithm, each process is dispatched to the processor (CPU) on a “first in, first out” (FIFO) basis with a fixed time quantum.

Each time quantum is typically 10-20ms. Modern processor (CPU) clock frequencies are typically greater than 2GHz, which implies clock periods of 5×10$^{-7}$ms. This shows that the given time quantum is relatively large compared to a typically processor’s (CPU’s) clock period.

If a process experiences a timeout, this will mean that it has run over its fixed time quantum. In which case, the process will be interrupted and returned to the back of the queue.

A system designer may wish to choose a time quantum that is most appropriate for a given system. This may be done by measuring the average service time and waiting time for the processes that will be running on the system and design the fixed time quantum around these figures. It may be that a system designer wishes to minimise the number of processes that are interrupted by another process.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/round-robin.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{RR}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.2935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\begin{longtabu} to \textwidth {|X[1,c]|X[1,c]|X[1,c]|}
	    \hline
	    \textbf{Process} & \textbf{Arrival Time} & \textbf{Service Time}
	    \\ \hline
	    A & 0 & 3
	    \\ \hline
	    B & 2 & 6
	    \\ \hline
	    C & 4 & 4
	    \\ \hline
	    D & 6 & 5
	    \\ \hline
	    E & 8 & 2
		\\ \hline
	\end{longtabu}
  \end{minipage}
  \begin{minipage}{0.7\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/temporal-diagram-rr-1.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Temporal diagram for RR with a fixed time quantum of 1 (q = 1)}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.2935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\begin{longtabu} to \textwidth {|X[1,c]|X[1,c]|X[1,c]|}
	    \hline
	    \textbf{Process} & \textbf{Arrival Time} & \textbf{Service Time}
	    \\ \hline
	    A & 0 & 3
	    \\ \hline
	    B & 2 & 6
	    \\ \hline
	    C & 4 & 4
	    \\ \hline
	    D & 6 & 5
	    \\ \hline
	    E & 8 & 2
		\\ \hline
	\end{longtabu}
  \end{minipage}
  \begin{minipage}{0.7\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/temporal-diagram-rr-4.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Temporal diagram for RR with a fixed time quantum of 4 (q = 4)}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Simple to implement}.
    &
    \textbf{Heavy overhead} due to continuous context switches.
    \\ \hline
  	\textbf{Suitable for some types of computer systems}, such as those which will be running processes of similar priority and size.
    &
    \textbf{Does not consider the priority of a process} and therefore the important processes may not be completed quickly.
    \\ \hline
    &
    \textbf{Does not consider the size of a process} and therefore, if processes are of varying sizes, there may be inefficiencies since a single process may take a long time to complete thus leaving the user waiting before they can perform any other actions.
	\\ \hline
\end{longtabu}


\section*{Multi-level queueing}

\subsection*{Definition}

\textbf{Multi-level queueing} is a queue with a predefined number of levels which consist of several independent queues.


\subsection*{How it works}

Multi-level queueing makes use of other existing scheduling algorithms.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-2/multi-level-queueing.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Multi-level queueing}
  \end{minipage}}
\end{figure}

Each queue has a different priority; the top queue has the highest priority and the bottom queue has the lowest priority. Processes are able to move between queues if their priority changes.

There is some form of inter-queue scheduling policy that governs the assignment of processes from each queue to the processor (CPU).

The queues in a multi-level queueing system may differ between operating system (OS). For example, the scheduler used by the Minix operating system (OS) uses multi-level queueing and implements 16 queues.

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Allows scheduling optimisation} as a system designer may be able to leverage the advantages of a range of different scheduling algorithms.
    &
    \\ \hline
  	\textbf{Maintains common processes} as it is possible to split processes in to different queues depending on their nature. For example, input/output processes could be in one queue while processor (CPU) processes are in another queue.
    &
    \\ \hline
    \textbf{Helps to prevent bottlenecks} because input/output (I/O) devices are slower than the processor speed and therefore maximising processes involving input/output (I/O) devices ensures that these devices are continuously busy.
    &
	\\ \hline
\end{longtabu}


\chapter{Threads and Concurrency}

\section{What are threads?}

\section*{Definition}

A \textbf{thread} is an independent path/sequence of execution with in a process and can be managed independently by a scheduler. A process many contain many threads.


\section*{Multi-threading}

\subsection*{How it works}

As mentioned in the previous section, a process (or job/task) shows a program in execution and is a particular instance of a program. By default, these processes are run by means of “single execution thread”.

However, different parts of the same process could be parallelised in order to allow multi-threading.

Multi-threading provides a way of improving application performance and therefore improving the efficiency and/or usability of a computer system.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/single-threaded-vs-multi-threaded.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Single-threaded vs multi-threaded}
  \end{minipage}}
\end{figure}


\subsection*{Example}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.4935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/microsoft-word.png}
  \end{minipage}
  \begin{minipage}{0.5\dimexpr \textwidth-2\fboxsep-2\fboxrule}
	In this example, a thread could be assigned to each of the following tasks:
	\begin{itemize}
		\item user input, such as keyboard and mouse input;
		\item auto-saving document;
		\item spell-checking document; and
		\item printing in the background.
	\end{itemize}
	This is possible as all of these tasks can be run in parallel as they do not require information from one another.
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Example of multi-threading in Microsoft Word}
  \end{minipage}}
\end{figure}


\section*{Threads vs processes}

\subsection*{Comparison}

Threads and processes share some similarities however, there are also some distinct differences.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/single-threaded-process.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Single-threaded process}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/multi-threaded-process.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Multi-threaded process}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/process-table-and-control-block.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Process table and process control blocks}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {|X[0.8,c]|X[2,l]|X[2,l]|}
	    \hline
	     & \textbf{Threads} & \textbf{Processes}
	    \\ \hline
		\multirow{7}{*}{Similarities}
		& Sequential flow of control with start and end.
		& Sequential flow of control with start and end.
		\\
		\cline{2-3} 
		& At any time, a thread has a single point of execution.
		& At any time, a process has a single point of execution.
		\\
		\cline{2-3} 
		& Has its own execution context, stack (history) and program counter stored in a thread control block (TCB).
		& Has its own execution context, stack (history) and program counter stored in a process control block (PCB).
		\\
		\cline{2-3} 
		& Follows the three-state model in which the thread can be running, blocked or ready.
		& Follows the three-state model in which the process can be running, blocked or ready.
		\\
		\cline{2-3} 
		& Context switching can happen for threads.
		& Context switching can happen for processes.
		\\
		\cline{2-3} 
		& A thread can spawn another thread.
		& A process can spawn another process.
		\\
		\cline{2-3} 
		& A thread is often called a lightweight process. &
		\\ \hline
		\multirow{5}{*}{Differences}
		& A thread cannot exist on its own, instead it exists within a process.
		& A process does not require a parent entity.
		\\
		\cline{2-3} 
		& Usually created and/or controlled by a process.
		& A process is not typically created and/or controlled by another process.
		\\
		\cline{2-3} 
		& Threads can share process properties, including memory and open files.
		& Processes cannot share process properties with other processes.
		\\
		\cline{2-3} 
		& Inexpensive creation and context switching as does not require separate address space.
		& Expensive creation and context switching as requires separate address space.
		\\
		\cline{2-3} 
		& When running multiple threads concurrently, they share an address space.
		& When running multiple processes concurrently, they are resources, such as memory, disk and printers.
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Threads vs processes}
  \end{minipage}}
\end{figure}


\subsection*{Properties}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
	    \hline
		\textbf{Per process items}
		& \textbf{Per thread items}
		\\ \hline
		Address space & Program counter
		\\ \hline
		Global variables & Registers
		\\ \hline
		Open files & Stack
		\\ \hline
		Child processes & State
		\\ \hline
		Pending alarms &
		\\ \hline
		Signals and signal handlers &
		\\ \hline
		Accounting information &
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Threads vs processes}
  \end{minipage}}
\end{figure}

Process properties are shared between threads.
Thread properties are local and private to each thread.


\section{Sequential and concurrent programming}

\section*{Sequential programming}

\subsection*{Definition}

\textbf{Sequential programming} is the traditional activity of constructing a computer program using a sequential programming language.


\subsection*{How it works}

This involves a programming methodology that assumes statements are executed in order/sequence.

Programs written using sequential programming are assumed to execute on a single-CPU system and have a single thread of control.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/sequential-program.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Sequential program}
  \end{minipage}}
\end{figure}


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{No additional support required from the programming language}.
    &
    \textbf{Lower processor throughput than concurrent programming} as it cannot benefit from multitasking or concurrent processing.
    \\ \hline
  	\textbf{No additional support required from the operating system} as most old-school operating systems were generally single-threaded and therefore later generations of operating systems typically inherit this functionality.
    &
    \textbf{Multiple computer systems that each have their own CPU may yield a higher cost than multi-CPU systems} as more will be spent on resources, such as the power supply and motherboard, that could be otherwise shared in a multi-CPU system.
    \\ \hline
    &
    \textbf{Lower reliability than a multi-CPU system} because, in the case of the failure of the processor, there is no redundancy.
	\\ \hline
\end{longtabu}


\section*{Concurrent programming}

\subsection*{Definition}

\textbf{Concurrent programming} is the activity of constructing a computer program that takes advantage of concurrency allowed by the use of multiple threads of control.


\subsection*{How it works}

Multiple threads of control allow a given process to perform multiple computations in parallel and to control simultaneous external activities.

The program may be run on both:
\begin{longtabu} to \textwidth { X[1.5,l] X[0.2,l] X[7,l]}
	\textbullet a single-CPU system
	& -- &
	where the computer program will take advantage of multitasking; and
	\\
	\textbullet a multi-CPU system
	& -- &
	where the computer program will take advantage of true parallelism.
\end{longtabu}


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Increase processor throughput} due to the use of multitasking in a single-CPU system or parallel processing in a multi-CPU system.
    &
    \textbf{Requires support from the programming language} as it must implement techniques to deal with multitasking on a single-CPU system and/or parallel processing on a multi-CPU system.
    \\ \hline
  	\textbf{A multi-CPU system generally yields a lower cost than using multiple CPUs across multiple computer systems} because the processors share resources such as the power supply and motherboard.
    &
    \textbf{Requires support from the operating system} as it must support multi-threading in order to allow multitasking on a single-CPU system and/or interface and manage multiple CPU units on a multi-CPU system.
    \\ \hline
    \textbf{Increased reliability in a multi-CPU system} because failure of one processor does not affect the other processors, instead the computer system may experience lower performance until fixed.
    &
	\\ \hline
\end{longtabu}


\section{Sequential execution}

\section*{Definition}

Sequential execution is where the execution of threads in a sequential program is executed in sequence/order with no overlapping.


\section*{Order and precedence}

\subsection*{Explanation}

In sequential execution, there is only one possible sequence of execution. This is because a sequential program gives the system strict instructions on the order of executing the statements in the program.


\subsection*{Importance}

For example, a simple hypothetical program could be:
\begin{itemize}
	\item[] P;
	\item[] Q;
	\item[] R;
\end{itemize}

This tells the computer system that the statements must be executed in the order they are written, such that:
\begin{itemize}
	\item P must precede Q; and
	\item Q must precede R.
\end{itemize}


\subsection*{High level}

The importance of the order of precedence can be highlighted by demonstrating this idea in a high-level programming language.

Given the following program written in a high-level language:
\begin{itemize}
	\item[] x = 1;
	\item[] y = x + 1;
	\item[] x = y + 2;
\end{itemize}it is possible to see that the final values of x and y depend on the order of execution of the statements.


\subsection*{System level}

Given the following program written in a high-level language:
\begin{itemize}
	\item[] x = 1; \textbf{P}
	\item[] y = x + 1; \textbf{Q}
	\item[] x = y + 2; \textbf{R}
\end{itemize}
where each statement is assigned a letter respectively, each statement may be compiled in to several machine instructions.

Statement \textbf{P} is treated as a single machine instruction:
\begin{itemize}
	\item \textbf{P1}: store 1 at the memory address of x.
\end{itemize}

Statement \textbf{Q} is broken in to three machine instructions:
\begin{itemize}
	\item \textbf{Q1}: load the value of x in to a CPU register;
	\item \textbf{Q2}: increment the value in this register by 1; and
	\item \textbf{Q3}: store the value in this register at the memory address of y.
\end{itemize}

Statement \textbf{R} is broken in to three machine instructions:
\begin{itemize}
	\item \textbf{R1}: load the value add of y in to a CPU register;
	\item \textbf{R2}: increment the value in this register by 2; and
	\item \textbf{R3}: store the result at the memory address of x.
\end{itemize}


\section*{The nature of sequential execution}

The execution of statements \textbf{P}, \textbf{Q} and \textbf{R} at the program level (or high-level) as

	\indent \textbf{P} $\rightarrow$ \textbf{Q} $\rightarrow$ \textbf{R}
	
implies that the execution at the system level is as follows

	\indent \textbf{P1} $\rightarrow$ \textbf{Q1} $\rightarrow$ \textbf{Q2} $\rightarrow$ \textbf{Q3} $\rightarrow$ \textbf{R1} $\rightarrow$ \textbf{R2} $\rightarrow$ \textbf{R3},
	
given that \textbf{P} is compiled to a single machine instruction, whilst \textbf{Q} and \textbf{R} are compiled to three machine instructions – as seen on page 40.

Sequential execution has the following assumptions:
\begin{longtabu} to \textwidth { X[1.7,l] X[0.2,l] X[7,l]}
	\textbullet total ordering & -- &
	there is single-threaded computation, and therefore no overlap in the execution of the statements;
	\\
	\textbullet deterministic & -- &
	the same input will always result in the same output; and
	\\
	\textbullet sequence & -- &
	users will specify a strict sequence of steps required in order to achieve a desired goal.
\end{longtabu}
However, this does not apply in many practical applications, for which a sequence of steps is not required.


\section{Introduction to concurrent execution}

\section*{Definition}

\textbf{Concurrent execution} is where the execution of threads in a concurrent program is occurring asynchronously, meaning that the order in which tasks are executed is not predetermined.


\section*{The squares example}

In this hypothetical example, a person desires to have a list with the results of all of the squares (2$^{n}$) from 1 to 100000. 

A group of 100000 people are spilt in to heavily uneven teams and assigned the same task to complete all of the calculations in order to achieve the desired result.

It is given that each calculation takes n amount of time.

\begin{longtabu} to \textwidth {| X[1,l] | X[2,l] | X[1,l] | X[2,l] |}
    \hline
    \multicolumn{2}{|c|}{\textbf{Team 1}}
    & \multicolumn{2}{|c|}{\textbf{Team 2}}
    \\ \hline
    Number of members & 1
    & Number of members & 99999
    \\ \hline
    Strategy &
    One person should complete all of the calculations.
    & Strategy &
    Each member is assigned a number between 1 to 100000.

	Each member should calculate the respective square for the number they are assigned.
	\\ \hline
    Time taken & 100000n
    & Time taken & n
	\\ \hline
\end{longtabu}

This shows that Team 2 was 100000x faster than Team 1. This was because it was possible to decompose the larger task in to smaller sub-tasks and assign each of those tasks to a separate resource, which in this case is one person.

This example forms that basic concept of concurrent execution.


\section*{The nature of concurrent execution}

Concurrent execution dismisses many of the assumptions required for sequential execution (page 41).

Calculations may be carried out without total ordering. As a result, calculations may be carried out in parallel and overlapping is therefore allowed.

In the example above, each individual person in team 2 carried out their operations in sequence.

In the example above, the operations in the whole computation can be viewed as being in partial order. However, the order does not matter here because there is no dependency between the calculations. This is because the output from any given calculation is not required as an input to any other given calculation.

However, in general, concurrent execution is non-deterministic, and therefore the same input generally means different output due to ordering. This is because there are many cases where the order of operation does matter.


\section{Interleaving}

\section*{Why is interleaving required?}

Concurrent execution on a computer system with a multi-core CPU or multiple CPUs can make use of parallel processing in order to run threads asynchronously. However, this is not possible on a computer system with a single-CPU that consists of only one core.

As a result, interleaving is used in order to switch execution between threads.

It is important to note that the operations within each thread are strictly ordered, but the interleaving of the operations are not ordered and are interleaved in an unpredictable order.


\section*{Calculating interleavings}

\subsection*{Formula}

It is possible to calculate the number of interleavings given the formula:
\begin{equation*}
	\text{number of interleavings} = \frac{t_{1} + t_{2} + ... + t_{n}}{t_{1}!t_{2}!...t_{n}}
\end{equation*}
where
\begin{itemize}
	\item $t_{n}$ represents the number of statements/operations in each thread.
\end{itemize}

For example, in a concurrent program that has two threads, the formula may be adjusted to:
\begin{equation*}
	\text{number of interleavings} = \frac{(n + m)!}{n!m!}
\end{equation*}
where
\begin{itemize}
	\item $n$ represents the number of statements/operations in the first thread ($t_{1}$); and
	\item $m$ represents the number of statements/operations in the second thread ($t_{2}$).
\end{itemize}


\subsection*{Example}

A high-level concurrent program may spawn new threads.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/concurrent-program-spawing-threads.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Concurrent program spawning threads $t_{1}$ and $t_{2}$}
  \end{minipage}}
\end{figure}

In this example, the concurrent program spawns the threads $t_{1}$ and $t_{2}$ where:
\begin{longtabu} to \textwidth { X[1.5,l] X[0.2,l] X[3,l]}
	\textbullet $t_{1}$ has three statements & -- &
	A, B and C; and
	\\
	\textbullet $t_{2}$ has two statements & -- &
	S and T.
\end{longtabu}

There are two threads and therefore it is possible to use the adjusted formula to calculate the number of interleavings in this concurrent program:

\begin{equation*}
	\begin{aligned}
		\text{number of interleavings} & = \frac{(n + m)!}{n!m!} \\
		\text{number of interleavings} & = \frac{(3 + 2)!}{3! \times 2!} \\
		\text{number of interleavings} & = \frac{6!}{3! \times 2!} \\
		\text{number of interleavings} & = \frac{6\times5\times4\times3\times2\times1}{(3\times2\times1)\times(2\times1)} \\
		\text{number of interleavings} & = \frac{120}{6\times2} \\
		\text{number of interleavings} & = \frac{120}{12} \\
		\text{number of interleavings} & = 10
	\end{aligned}
\end{equation*}

There are 10 possible interleavings, thus yielding 10 possible different execution sequences.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/possible-execution-sequences.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Visual representation of the possible execution sequences}
  \end{minipage}}
\end{figure}

A run of the program corresponds to an interleaving sequence. Each interleaving sequence determines a unique sequence of executing the statements. Repeated runs with the same input will likely trace different interleavings.


\subsection*{Growth of interleavings}

The number of interleavings grows extremely quickly given an increase in:
\begin{itemize}
	\item the number of threads in the concurrent program; or
	\item the number of statements/operations in one or more of the concurrent program’s threads.
\end{itemize}

This can be demonstrated by increasing the number of operations in the previous example:
\begin{longtabu} to \textwidth { X[2,l] X[0.2,l] X[3,l]}
	\textbullet $t_{1}$ now has four statements  & -- &
	A, B, C and D; and
	\\
	\textbullet $t_{2}$ now has five statements  & -- &
	S, T, U, V and W.
\end{longtabu}
and therefore:
\begin{equation*}
	\begin{aligned}
		\text{number of interleavings} & = \frac{(n + m)!}{n!m!} \\
		\text{number of interleavings} & = \frac{(4 + 5)!}{4!\times5!} \\
		\text{number of interleavings} & = \frac{9!}{4!\times5!} \\
		\text{number of interleavings} & = \frac{9\times8\times7\times6\times5\times4\times3\times2\times1}{(4\times3\times2\times1)\times(5\times4\times3\times2\times1)} \\
		\text{number of interleavings} & = \frac{362880}{24\times120} \\
		\text{number of interleavings} & = \frac{362880}{2880} \\
		\text{number of interleavings} & = 126
	\end{aligned}
\end{equation*}


\newpage

\section{User and kernel threads}

\section*{User threads}

User threads are created and managed by a user level library, typically without the knowledge of the kernel.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/user-threads.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{User threads}
  \end{minipage}}
\end{figure}

The diagram shows that:
\begin{itemize}
	\item all of the threads for a given process is present within the user space; and
	\item the thread table is present within the process.
\end{itemize}

User threads are:
\begin{itemize}
	\item fast to create and manage; and
	\item portable to any operating system (OS).
\end{itemize}

If one user thread is blocked, all other threads in the same process are also blocked. For example, in a word processor application, a thread that handles a printing event would block all other threads and therefore prevent the user from interacting with other aspects of the application.

Multi-threaded applications cannot take advantage of parallel execution on computer systems with a multi-core CPU or computer systems with multiple CPUs.

\newpage

\section*{Kernel threads}

Kernel threads are directly managed and supported by the operating system’s (OS’s) kernel.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/kernel-threads.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Kernel threads}
  \end{minipage}}
\end{figure}

The diagram shows that:
\begin{itemize}
	\item all of the threads for a given process is present within the user space; and
	\item the thread table is present within the kernel space, rather than the process itself or the user space.
\end{itemize}

Kernel threads are:
\begin{itemize}
	\item slower to create and manage than user threads; and
	\item specific to the operating system (OS).
\end{itemize}

If one user thread is blocked, all other threads in the same process are scheduled and not blocked. For example, in a word processor application, a thread that handles a printing event would no longer block all other threads and therefore would allow the user to interacting with other aspects of the application whilst the printing event occurs.

Can take advantage of parallel execution on computer systems with a multi-core CPU or computer systems with multiple CPUs.



\section{Multi-threading models}

\section*{Why is multi-threading mapping required?}

The kernel is generally not aware of the user threads present in a process. Therefore, a thread library must map user threads to kernel threads.


\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/multi-threading-mapping.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Multi-threading mapping}
  \end{minipage}}
\end{figure}

The diagram shows that there must be some relationship between the user threads and the kernel threads. This relationship may defined using different mappings, including:
\begin{itemize}
	\item many-to-one;
	\item one-to-one; and
	\item many-to-many.
\end{itemize}


\section*{Many-to-one mapping}

\subsection*{How it works}

All user threads from each process map to one kernel thread.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/many-to-one-mapping.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Many-to-one mapping}
  \end{minipage}}
\end{figure}


\subsection*{Evalution}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Portable} as there are few system dependencies.
    &
    \textbf{No parallel execution of threads}.
    \\ \hline
    &
    \textbf{No concurrency} as all threads in a process are blocked if another thread is blocked, for example if the thread is waiting for an input/output (I/O) interrupt.
	\\ \hline
\end{longtabu}


\section*{One-to-one mapping}

\subsection*{How it works}

Each user thread maps to a single kernel thread.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/one-to-one-mapping.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{One-to-one mapping}
  \end{minipage}}
\end{figure}


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Concurrency} as all threads in a process are not blocked if any given thread becomes blocked.
    &
    \textbf{Slow} as there is management overhead because the kernel is involved for every user thread.
    \\ \hline
    \textbf{Performance} as it can take advantage of multiple CPUs.
    &
    \textbf{Restricted} as there is typically a limit on the number of threads.
	\\ \hline
    &
    \textbf{Creating user threads requires the corresponding kernel support}.
	\\ \hline
\end{longtabu}


\section*{Many-to-many mapping}

\subsection*{How it works}

Many user threads multiplex to an equal or smaller number of kernel threads.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-3/many-to-many-mapping.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Many-to-many mapping}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \textbf{Performance} as it can take advantage of multiple CPUs.
    &
    \textbf{Complexity} and therefore implementation difficulties.
    \\ \hline
    \textbf{Flexible} as there is no limit on the number of threads.
    &
	\\ \hline
\end{longtabu}


\newpage

\section{Evaluation of concurrent programming}
\begin{longtabu} to \textwidth {|X[1,l]|X[1,l]|}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
    \\ \hline
    \begin{wrapfigure}{l}{4cm}
		\includegraphics[width=4cm]{images/chapter-3/parallelism.png}
	\end{wrapfigure} 
    \textbf{Parallelism.} It improves the efficiency of program execution in computer systems with multiple CPUs by allows tasks/operations to be split up and executed independently on each CPU.
    &
    \textbf{Debugging complexity} as concurrent programs are non-deterministic and therefore it can be difficult to trace a problem/bug in the code as the same input will generally not result in the same output.  
    \\ \hline
    \begin{wrapfigure}{l}{0.8cm}
		\includegraphics[width=0.8cm]{images/chapter-3/multi-tasking.png}
	\end{wrapfigure}
    \textbf{Multi-tasking.} It improves the utilisation of the CPU in a computer system that only has a single CPU. This allows multiple tasks/operations to run alongside each other and appear to be processed simultaneously.
    &
    \textbf{No protection between threads}.
    \\ \hline
    \textbf{Increases application responsiveness}, for example, in a word processor application one thread could be responsible for responding to user input/output (I/O) while other threads perform tasks in the background.
    &
    \textbf{Concurrent processes must interact with each other} in order to share resources or exchange data.
    \\ \hline
    \textbf{Suited to some applications} as there are some practical applications that are non-deterministic and concurrent as the order of program operations is determined by other external events. This is useful for applications that need to handle multiple events.
    &
    \textbf{Synchronisation must be promoted} in order to determine when, how and with what language abstractions computation events can be synchronised in order to eliminate unacceptable outputs.
    \\ \hline
    &
    \textbf{Distribution must be taken care of} in order to consider how threads can be distributed among a number of CPUs and how one thread is able to interact with another thread on a different CPU.
    \\ \hline
    &
    \textbf{Error-prone}.
	Examples of major concurrent programming errors include:
	\begin{itemize}
		\item Therac-25	- A computerised radiation therapy machine whose errors contributed to accidents causing deaths and serious injuries.
		\item Mars Rover Pathfinder	– Problems with interaction between concurrent tasks caused periodic software resets, thus reducing availability for exploration.
	\end{itemize}
	\\ \hline
\end{longtabu}


\chapter{Synchronisation and Mutual Exclusion}

\section{Race condition}

\section*{Definition}

A \textbf{race condition} describes the competition for resources in a critical section caused by interleaving/thread interference.


\section*{Why do race conditions happen?}

Race conditions occur due to interleaving/thread interference.

\textbf{Interleaving/thread interference} describes an undesired outcome resulting from non-deterministic, concurrent usage of shared resources.

This happens because, in general, concurrent execution is non-deterministic, and therefore the same input generally means different output due to ordering. This is because there are many cases where the order of operation does matter.


\section*{Examples}

\subsection*{Racing for memory access}

A race condition may occur when two threads attempt to access the same location memory, such as registers or RAM, at the same time.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/concurrent-program-spawning-threads.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Concurrent program spawning threads $t_{1}$ and $t_{2}$}
  \end{minipage}}
\end{figure}

In this example, the two threads $t_{1}$ and $t_{2}$ manipulate the same variable where:
\begin{itemize}
	\item $t_{1}$ increments the variable $c$; and
	\item $t_{2}$ decrements the variable $c$.
\end{itemize}
As seen before (page 40), each statement may be compiled in to several machine instructions.

The increment ($c++$) instruction is broken in to three machine instructions:
\begin{itemize}
	\item retrieve $c$;
	\item increment retrieved value; and
	\item store result in $c$.
\end{itemize}

The decrement ($c--$) instruction is also broken in to three machine instructions:
\begin{itemize}
	\item retrieve $c$;
	\item decrement retrieved value; and
	\item store result in $c$.
\end{itemize}

As a result, one interleaving possibility is as follows:
\begin{itemize}
	\item $t_{1}$: retrieve $c$;
	\item $t_{2}$: retrieve $c$;
	\item $t_{1}$: increment retrieved value; (result is $1$)
	\item $t_{2}$: decrement retrieved value; (result is $-1$)
	\item $t_{1}$: store result in $c$; ($c$ is now 1)
	\item $t_{2}$: store result in $c$; ($c$ is now -1)
\end{itemize}

This example shows that the race condition has caused the result from thread $t_{1}$ to be lost as it has been overwritten by the result from thread $t_{2}$.


\subsection*{Racing for peripheral access}

A race condition may also occur when two threads attempt to access the same peripheral, such as a printer spooler directory, at the same time.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/printer-spooler-directory.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Printer spooler directory}
  \end{minipage}}
\end{figure}

In this example, the two processes $A$ and $B$ attempt to access the printer spooler directory at the same time:
\begin{itemize}
	\item the next available printer job slot is $7$;
	\item process $A$ and $B$ access printer job slot $7$ simultaneously;
	\item process $A$ reads printer job slot $7$ and a timer interrupt occurs that causes a context switch to process $B$ before process $A$ has opportunity to store any data;
	\item process $B$ reads printer job slot $7$ and stores its job data and increments the values; and
	\item another timer interrupt occurs that causes a context switch to process $A$ that then stores its job at printer job slot $7$.
\end{itemize}

This example shows that the race condition has caused the job data stored in the printer spooler directory by process $B$ to be lost as it has been overwritten by the job data from process $A$.


\section{Inter-process synchronisation}

\section*{Definition}

\textbf{Inter-process synchronisation} involves techniques that are designed to prevent race conditions and allows threads/processes to share resources.


\section*{Behaviour of threads}

Threads in a computer system may behave in two possible ways:
\begin{itemize}
	\item competing -- two or more processes compete for the same computing resource, for example access to a particular memory cell; or
	\item cooperating -- two or more processes may need to communicate with one another, thus causing information to be passed from one to the other.
\end{itemize}

Inter-process synchronisation is required to manage both threads that are competing and threads that are cooperating.

An operating system (OS) itself contains both threads that are competing and threads that are cooperating.


\section*{How mutual exclusion works}

The solution to preventing race conditions is by implementing mutual exclusion on any given critical section/region.

The \textbf{critical section/region} is code in a process that involves sensitive operations on a shared resource.

\textbf{Mutual exclusion} is the requirement that one thread of execution never enters its critical section/region at the same time that another concurrent thread of execution enters its own critical section/region.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/mutual-exclusion.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Mutual exclusion on critical section/region}
  \end{minipage}}
\end{figure}

When a thread/process enters its critical section/region, no other thread/process may also enter its critical section/region. 

This is demonstrated in the diagram above:
\begin{itemize}
	\item at time interval $T_{1}$, process $A$ enters its critical section/region;
	\item at time interval $T_{2}$, process $B$ attempts to enter its critical section/region;
	\item process $B$ is blocked from entering its critical section/region until process $A$ leaves its critical section/region;
	\item at time interval $T_{3}$, process $A$ leaves its critical section/region and therefore process $B$ is allowed to enter its critical section/region; and
	\item at time interval $T_{4}$, process $B$ leaves its critical section/region.
\end{itemize}

This shown that mutual exclusion is enforced as no two threads/processes are simultaneously inside their critical sections/regions.

For mutual exclusion to be effective:
\begin{itemize}
	\item no assumptions may be made about the speeds or the number of threads/processes;
	\item no threads/processes running outside its critical section/region may block other threads/processes, such that a thread/process that is not in its critical section/region cannot prevent other threads from entering their critical section/region; and
	\item no thread/process should have to wait forever to enter its critical section/region.
\end{itemize}

Mutual exclusion is a major design issue in operating systems (OSs) as consideration must be taken in order to prevent race conditions while maintaining parallelism and efficiency.


\section*{How mutual exclusion is implemented}

Mutual exclusion is implemented using semaphores.

A \textbf{semaphore} is a system tool used for the design of correct synchronisation protocols. This was introduced by Edsger Dijkstra in the 1962/1963. Semaphores are implemented using a variable or abstract data type and are used to control thread/process access to a resource. They are typically integer values that accept only non-negative values.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/semaphore-interaction.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Semaphore interaction on critical section/region}
  \end{minipage}}
\end{figure}

The diagram shows that semaphores allow the CPU to context switch between threads/processes when one becomes blocked.

It is convenient to write entry and exit protocols using a single atomic statement. This statement is atomic and therefore is indivisible, meaning that the statement cannot be interrupted.

As mentioned before, a semaphore, denoted by $S$, is an integer that takes only non-negative values. Only two atomic (indivisible) statements are permitted, as shown below.

\begin{longtabu*} to \textwidth {|X[0.5,l]|X[1,l]|X[1,l]|}
    \hline
	\textbf{Statement} & \textbf{Statement Implementation}
	& \textbf{Usage}
	\\ \hline
	$wait(s)$
	&
	\begin{verbatim}
	wait(s)
	{
	    if ( S > 0 )
	    {
	        S--;
	    }
	}
	\end{verbatim}
	&
	If a thread/process is in its non-critical section/region and wishes to enter its critical section/region, this statement will be performed.

	This means that the thread/process will be blocked until $S = 0$	evaluates to $True$.
	\\ \hline
	$signal(s)$
	&
	\begin{verbatim}
	signal(s)
	{
	    S++;
	}
	\end{verbatim}
	&
	If a thread/process is in its critical section/region, this statement will be performed.

	This helps to achieve mutual exclusion as it prevents $S = 0$ from evaluating to $True$ until the thread/process has left its critical section/region.
	\\ \hline
\end{longtabu*}

This is a good solution as there is no possibility for a race condition as these statements will always be enforced due to the face that they are atomic (indivisible) statements and cannot be interrupted.


\section{The producer-consumer problem}

\section*{Problem description}

The producer-consumer problem is a classical inter-process communication problem in which:
\begin{itemize}
	\item a producer repeatedly produces items and places them in to a buffer; and
	\item a consumer consumes the items one-by-one by taking them from the buffer.
\end{itemize}

This problem has the following requirements:
\begin{itemize}
	\item the buffer must be assumed to be first in, first out (FIFO);
	\item the producer may produce a new item only at a time when the buffer is not full;
	\item the consumer may consume an item only at a time when the buffer is not empty; and
	\item the process terminates when all items produced are eventually consumed.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/producer-consumer-problem.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{The producer-consumer problem}
  \end{minipage}}
\end{figure}

The problem arises when attempting to devise a method that is able to:
\begin{itemize}
	\item put the producer to “sleep” when the buffer is full to prevent further items being produced when there is no space in the buffer; and
	\item “wake” the consumer when the buffer is not empty as there is possibility to consumer when the buffer is not empty.
\end{itemize}


\section*{Possible solution}

This problem could be solved by keeping track of the number of items in the buffer.

This could be achieved by implementing loops in the producer class and consumer class.

\newpage

\begin{lstlisting}[title={Producer class}]
LOOP
{
	Produce item i         //produce item
	if ( itemCount == N )  //end of buffer
	{
		sleep(producer);
	}

	Put item i;            // place item in to buffer
	itemCount++;           // increment buffer count
	if ( itemCount == 1)   // buffer nearly empty
	{
		wakeup(consumer);
	}
}
\end{lstlisting}

\begin{lstlisting}[title={Consumer class}]
LOOP
{
	if ( itemCount == 0 )    // buffer empty
	{
		sleep(consumer);
	}

	Remove item j;           // remove item from buffer
	itemCount--;             // decrement buffer count
	if ( itemCount == N-1 )  // buffer has space
	{
		wakeup(producer);
	}
	Consume item j;          // consume item
}
\end{lstlisting}

The loop in the producer class would be running as one thread and the loop in the consumer thread would be running as another thread. These two threads would be running in parallel. As a result, if the threads in the solution are interleaved, a race condition may occur, which in turn, may cause a deadlock.


\subsection*{Deadlocks}

A \textbf{deadlock} occurs when two or more threads wait for each other to finish.

Four conditions must be hold simultaneously in order for a deadlock to occur:
\begin{itemize}
	\item mutual exclusion -- a resource can be assigned to, at most, one process at a time;
	\item hold and wait -- processes holding resources are permitted to request and wait for additional resources;
	\item no pre-emption	 -- resources previously locked cannot be forcefully unlocked by another process, instead they must be released by the holding process; and
	\item circular wait -- there must be a chain of processes, such that each member of the chain is waiting for a resource held by the next member of the chain, as shown in the diagram below.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/circular-wait.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Circular wait}
  \end{minipage}}
\end{figure}

A deadlock may occur in the possible solution described previously.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    Consumer reads $itemCount = 0$ and it evaluates to $True$, and therefore $sleep(consumer)$ needs to be called.
    
	$\downarrow$
	
	Just before $sleep(consumer)$ is called, the consumer is interrupted by a timer interrupt and the producer is resumed.
	
	$\downarrow$
	
	The producer places an item in to the buffer, such that $itemCount = 1$.
	
	$\downarrow$
	
	The producer tries to perform $wakeup(consumer)$ however, the consumer is already in “wakeup” mode. As a result, the call to $wakeup(consumer)$ is missed.
	
	$\downarrow$
	
	When the consumer resumes, it will call $sleep(consumer)$ and get trapped in “sleep” mode.
	
	$\downarrow$
	
	The producer will continue placing items in the buffer and call $sleep(producer)$ when the buffer is full.
	
	$\downarrow$
	
	There is now a deadlock as both threads are waiting for a $wakeup$ call from each other.
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Possible deadlock}
  \end{minipage}}
\end{figure}

This possible deadlock shows that another solution is required to effectively solve the producer-consumer problem.


\section*{Solving the problem using semaphores}

It is assumed that
\begin{lstlisting}
ItemsReady = 0
SpacesLeft = N  //size of buffer
\end{lstlisting}

\begin{lstlisting}[title={Producer class}]
LOOP
{
	Produce item i      // produce item
	Wait(SpacesLeft)    // decrement semaphore

	Put item i;         // place item in to buffer
	Signal(ItemsReady)  // increment
}
\end{lstlisting}

\begin{lstlisting}[title={Consumer class}]
LOOP
{
	Wait(ItemsReady)    // decrement semaphore

	Get item j;         // remove item from buffer
	Signal(SpacesLeft)  // increment semaphore
	Consume item i;     // consume item
}
\end{lstlisting}

If this solution uses semaphores correctly, then
\begin{equation*}
	\begin{aligned}
		\text{N = SpacesLeft + ItemsReady}
	\end{aligned}
\end{equation*}

as the producer will always be placing items in to the buffer when there are spaces available in the buffer.

However, this solution does not consider situations in which there are multiple producers and/or multiple consumers.


\newpage

\section*{The multiple producer-consumer problem}

\subsection*{Problem description}

The multiple producer-consumer problem is a classical inter-process communication problem in which:
\begin{itemize}
	\item multiple producer repeatedly produces items and places them in to a buffer; and
	\item multiple consumer consumes the items one-by-one by taking them from the buffer.
\end{itemize}

As with the previous producer-consumer problem, this problem has the following requirements:
\begin{itemize}
	\item the buffer must be assumed to be first in, first out (FIFO);
	\item the producers may produce a new item only at a time when the buffer is not full;
	\item the consumers may consume an item only at a time when the buffer is not empty; and
	\item the process terminates when all items produced are eventually consumed.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/multiple-producer-consumer-problem.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{The multiple producer-consumer problem}
  \end{minipage}}
\end{figure}

The problem arises when attempting to devise a method that is able to manage:
\begin{itemize}
	\item two producers placing items in to the same slot in the buffer; and
	\item two consumers removing items from the same slot in the buffer.
\end{itemize}
This is similar to the problem discussed in the printer spooler example (page n).

A race condition may also occur when producers attempt to access a variable at the same time.

To demonstrate the race condition, it is necessary to consider the following possible interleaving of the threads/processes:
\begin{itemize}
	\item two producers access the $SpacesLeft$ variable at the same time, which corresponds to decrementing the semaphore;
	\item both producers get the same next empty slot in the buffer at the same time; and
	\item both producers write in to the same slot.
\end{itemize}

This example shows that the race condition has caused the data stored in the buffer slot by the first producer to be lost as it has been overwritten by the data stored in the buffer slot by the second producer.

In order to ensure mutual exclusion when multiple users are involved, an additional semaphore must be introduced.


\subsection*{Mutex}

A \textbf{mutex} (or \textbf{binary semaphore}) is a semaphore with ownership that can only be released by its owner and is initially set to $1$.


\subsection*{Problem solution}

It is now possible to construct a solution, using a mutex (or binary semaphore), that will ensure mutual exclusion even when there are multiple producers and/or multiple consumers.

It is assumed that
\begin{lstlisting}
ItemsReady = 0
SpacesLeft = N  //size of buffer
\end{lstlisting}

\begin{lstlisting}[title={Producer class}]
LOOP
{
	Produce item i      // produce item
	Wait(SpacesLeft)    // decrement semaphore
	Wait(BusyBuffer)    // mutex

	Put item i;         // place item in to buffer
	Signal(BusyBuffer)  // release mutex
	Signal(ItemsReady)  // increment
}
\end{lstlisting}

\begin{lstlisting}[title={Consumer class}]
LOOP
{
	Wait(ItemsReady)    // decrement semaphore
    Wait(BusyBuffer)    // mutex

    Get item j;         // remove item from buffer
    Signal(SpacesLeft)  // increment semaphore
    Signal(BusyBuffer)  // release mutex
    Consume item i;     // consume item
}
\end{lstlisting}

The mutex $BusyBuffer$ has ownership and therefore can only be incremented/decremented by the same thread/process.

The order in which semaphores are incremented and decremented is essential. This can be demonstrated by inspecting the effect of switching around two statements in the Consumer class:
\begin{lstlisting}
Wait(ItemsReady)  //decrement semaphore
Wait(BusyBuffer)  //mutex
...
Wait(BusyBuffer)  //mutex
Wait(ItemsReady)  //decrement semaphore
\end{lstlisting}

This switching would cause …


\section{The dining philosophers problem}

\section*{Problem description}

The dining philosophers problem is a classical inter-process communication problem in which:
\begin{itemize}
	\item five philosophers are seated around a circular table eating and thinking; and
	\item each philosopher has a plate of spaghetti that they can eat with forks.
\end{itemize}

This problem has the following requirements:
\begin{itemize}
	\item the life of a philosopher consists of only alternating periods of eating and thinking;
	\item between each pair of plates is one fork;
	\item each philosopher needs two forks to eat the spaghetti; and
	\item no two philosophers may hold the same fork simultaneously.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/layout-of-table.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Layout of table}
  \end{minipage}}
\end{figure}

The problem arises when attempting to devise a method that is able to:
\begin{itemize}
	\item allow each philosopher to have alternating periods of eating and thinking; and
	\item not result in a deadlock.
\end{itemize}

It could be said that the problem requirement for each philosopher to need two forks to eat the spaghetti is somewhat artificial. As a result, we can substitute the spaghetti for rice and substitute chopsticks for forks.

The problem now has the following updated requirements:
\begin{itemize}
	\item the life of a philosopher consists of only alternating periods of eating and thinking;
	\item between each pair of plates is one chopstick;
	\item each philosopher needs two chopsticks to eat the rice; and
	\item no two philosophers may hold the same chopstick simultaneously.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/updated-layout-of-table.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Updated layout of table}
  \end{minipage}}
\end{figure}


\section*{Problem solutions}

\subsection*{Problem solution 1}

This problem can be solved using semaphores, using the following assumptions:
\begin{itemize}
	\item each philosopher is a different thread with a unique ID;
	\item one semaphore is implemented per chopstick; and
	\item chopsticks are identified by using the unique ID of a philosopher.
\end{itemize}

As chopsticks are identified by using the unique ID of a philosopher, it could be that:
\begin{itemize}
	\item the chopstick to the left of a given philosopher is $chopstick[i]$; and
	\item the chopstick to the right of a given philosopher is $chopstick[(i-1) + N) \% N].$
\end{itemize}
where $i$ is the ID of the philosopher and $N$ is the number of philosophers.

The identification of the chopsticks works as demonstrated by using Philosopher 1 as an example.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-4/philosopher-1.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Philosopher 1}
  \end{minipage}}
\end{figure}

The diagram shows that:
\begin{itemize}
	\item the chopstick to the left of Philosopher 1 is $chopstick[1]$; and
	\item the chopstick to the right of Philosopher 1 is $chopstick[0]$.
\end{itemize}

Using this example, it is possible to validate the chopstick identification formulas discussed before.

Given that $i = 1$ for Philosopher 1 and that $N = 5$ as there are five philosophers in total,
\begin{equation*}
	\begin{aligned}
		\text{left} & = \text{chopstick[i]} \\
		\text{left} & = \text{chopstick[1]} \\
		\text{right} & = \text{chopstick[(i-1) + N) \% N]} \\
		\text{right} & = \text{chopstick[(1-1) + 5) \% 5]} \\
		\text{right} & = \text{chopstick[(0 + 5) \% 5]} \\
		\text{right} & = \text{chopstick[5 \% 5]} \\
		\text{right} & = \text{chopstick[0]} \\
	\end{aligned}
\end{equation*}
This shows that the chopstick identification formulas work for Philosopher 1.

\begin{lstlisting}[title={Producer class}]
LOOP
{
	think();
	wait(chopstick[left]);     // take left chopstick
	wait(chopstick[right]);    // take right chopstick
	eat();
	signal(chopstick[left]);   // release left chopstick
	signal(chopstick[right]);  // release right chopstick
}
\end{lstlisting}

However, this solution has the possibility to cause a race condition.

This can be demonstrated in the situation where all five philosophers wish to eat at the same time and therefore all take their left chopsticks:
\begin{itemize}
	\item Philosopher 0 takes $chopstick[left]$;
	\item Philosopher 1 takes $chopstick[left]$;
	\item Philosopher 2 takes $chopstick[left]$;
	\item Philosopher 3 takes $chopstick[left]$; and
	\item Philosopher 4 takes $chopstick[left]$.
\end{itemize}

This causes a race condition as:
\begin{itemize}
	\item each philosopher will now be waiting to take $chopstick[right]$;
	\item no philosopher can take $chopstick[right]$ as this chopstick is the subsequent philosopher’s $chopstick[left]$ and this has already been taken; and
	\item no philosopher can perform their $eat$ function and therefore no chopsticks will be released as the $signal$ functions are only performed after the $eat$ function has completed.
\end{itemize}

This shows that, if the threads in the solution are interleaved, a race condition may occur. In this case, a circular wait is caused and therefore there is a deadlock.


\subsection*{Possible solution 2}

As shown in the multiple producer-consumer problem, a mutex (or binary semaphore) can be introduced to prevent this deadlock.

\begin{lstlisting}[title={Producer class}]
LOOP
{
	think();
	wait(busy);                // mutex
	wait(chopstick[left]);     // take left chopstick
	wait(chopstick[right]);    // take right chopstick
	eat();
	signal(chopstick[left]);   // release left chopstick
	signal(chopstick[right]);  // release right chopstick
	signal(busy);              // release mutex
}
\end{lstlisting}

This solves the deadlock as the mutex (or binary semaphore) signals the critical section/region and prevents other philosophers from attempting to take a chopstick that is currently in use by another philosopher.

Although this solution is deadlock-free, it has a performance bug. The mutex means that only one philosopher can be eating at any instant and, with five chopsticks available, it should be possible to allow two philosophers to eat at the same time. As a result, there are more efficient solutions to this problem that achieve maximum parallelism.

\subsection*{Final revision solution}

This solution is deadlock-free and allows the maximum parallelism for an arbitrary number of philosophers.

\begin{lstlisting}[title={Producer class}]
#define N         5                // number of philosophers
#define LEFT      (i + N - 1) % N  // ID of i's left neighbour
#define RIGHT     (i + 1) % N      // ID of i's right neighbour
#define THINKING  0                // philosopher is thinking
#define HUNGRY    1                // philosopher is trying to acquire
                                   // chopsticks
#define EATING    2                // philosopher is eating

typedef int semaphore              // semaphores are a special kind of
                                   // integer
int state[N];                      // array to keep track of philosopher's
                                   // state             
semaphore mutex = 1;               // mutual exclusion for critical regions
semaphore s[N];                    // one semaphore per philosopher

// i: philosopher unique ID, from 0 to N-1
void philosopher (int i)
{
	while (TRUE)                   // repeat indefinitely
	{
		think();                   // philosopher is thinking
		take_chopsticks(i);        // acquire two chopsticks or be blocked
		eat();                     // philosopher is eating
		put_chopsticks(i);         // place both chopsticks back on the table
	}
}

// i: philosopher unique ID, from 0 to N-1
void take_chopsticks(int i)
{
	wait(&mutex);                  // enter critical section/region
	state[i] = HUNGRY;             // record fact that philosopher i is hungry
	test(i);                       // attempt to acquire two chopsticks
	signal(&mutex);                // exit critical section/region
	wait(&s[i]);                   // block if chopsticks were not acquired
}

// i: philosopher unique ID, from 0 to N-1
void put_chopsticks(int i)
{
	wait(&mutex);                  // enter critical section/region
	state[i] = THINKING;           // record fact that philosopher i is
	                               // thinking
	test(LEFT);                    // check if left neighbour can now eat
	test(RIGHT);                   // check if right neighbour can now eat
	signal(&mutex);                // exit critical section/region
}

// i: philosopher unique ID, from 0 to N-1
void test(int i)
{
	if (state[i] == HUNGRY && state[LEFT] != EATING
		&& state[RIGHT] != EATING)
	{
		state[i] = EATING;         // record fact that philosopher i is hungry
		signal(&s[i]);             // exit critical section/region
	}
}
\end{lstlisting}

This solution uses the array state to keep track of whether a philosopher is:
\begin{itemize}
	\item eating;
	\item thinking; or
	\item hungry (trying to acquire chopsticks).
\end{itemize}

This represents an array of semaphores and each philosopher has its own $state$ array. This enables hungry philosophers to be blocked if the required chopsticks are currently busy.

A philosopher may move in to eating state only if neither neighbouring philosopher is eating. For example, Philosopher 1 cannot enter eating state if:
\begin{itemize}
	\item Philosopher 0 is currently in eating state; or
	\item Philosopher 2 is currently in eating state.
\end{itemize}


\chapter{Memory Management}

\section{Memory hierarchy}

\section*{Definition}

The \textbf{memory hierarchy} separates computer storage into a hierarchy based on response time. A computer system is usually composed by a layered memory system


\section*{Diagram}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/memory-hierarchy-pyramid.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Memory hierarchy pyramid}
  \end{minipage}}
\end{figure}

Higher layers correspond to faster devices that:
\begin{itemize}
	\item have lower capacity;
	\item require more power and generate more heat; and
	\item are more expensive.
\end{itemize}

Lower layers correspond to slower devices that:
\begin{itemize}
	\item have higher capacity;
	\item require less power and generate less heat; and
	\item are cheaper.
\end{itemize}

The temporary storage areas can be described as volatile; the data does not persist after power-down.

The permanent storage areas can be described as non-volatile; the data persists after power-down.


\section{Primary memory}

\section*{Definition}

\textbf{Primary memory} is volatile, meaning that the data contained within does not persist after power-down, and stores data and instructions for use by the CPU in currently running processes.


\section*{Registers}

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & Very small.
	\\ \hline
	\textbf{Speed} & Extremely fast.
	\\ \hline
	\textbf{Purpose} & Individual containers for single values.
	
	Almost all computers load data from a memory lower in the hierarchy into registers, where it is used for arithmetic operations and is manipulated or tested by machine instructions.
	\\ \hline
	\textbf{Location} & Inside the CPU.
	\\ \hline
\end{longtabu}

Registers are typically referred to by “name” (i.e. individual identifying code), not by address, as happens with other types of memory.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/registers.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Registers}
  \end{minipage}}
\end{figure}

There are two main types of registers:
\begin{itemize}
	\item generic registers -- allow the CPU to temporarily store data on which it will perform operations, and consequently data that results from those operations; and
	\item specialised registers -- manipulated in mostly the same fashion as generic registers but are used for specialised purposes.
\end{itemize}

Specialised registers include:
\begin{itemize}
	\item Instruction Register (IR) -- holds the instruction currently being executed;
	\item Memory Data Register (MDR) -- holds the piece of data that has been fetched from memory;
	\item Memory Address Register (MAR) -- holds the address of the next piece of memory to be fetched;
	\item Program Counter (PC) -- holds the location of the next instruction to be fetched from memory and is automatically incremented between supplying the address of the next instruction and the instruction being executed; and
	\item Accumulator (ACCU) -- used as the default location to store any calculations performed by the arithmetic and logic unit.
\end{itemize}

Generic registers are available to store any transient data required by the program.

For example, when a program is interrupted its state, the values stored in the specialised registers may be saved into the generic registers, ready for recall when the program is ready to start again.

In general, the more registers a CPU has available, the faster it can work.


\section*{Cache memory}

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & Small (KB/MB).
	\\ \hline
	\textbf{Speed} & Fast.
	\\ \hline
	\textbf{Purpose} & Serves as an intermediary between main memory and the registers.
	
	When data or instructions are fetched from main memory, they are copied to the cache for further use, and therefore, reduce the average cost (time or energy) to access data from the main memory.
	\\ \hline
	\textbf{Location} & Inside the CPU.
	\\ \hline
\end{longtabu}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/cache-memory.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Cache memory}
  \end{minipage}}
\end{figure}

Modern computers typically have a sub-hierarchy of cache memories (L1, L2, L3, L4, etc.), for example:
\begin{itemize}
	\item level 1 cache (L1)	 -- very fast and small size (2KB - 64KB); and
	\item level 2 cache (L2)	 -- fast and medium size (256KB – 2MB).
\end{itemize}


\section*{Main memory}

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & Medium (MB/GB).
	\\ \hline
	\textbf{Speed} & Fast.
	\\ \hline
	\textbf{Purpose} & Stores data and machine code currently being used.
	\\ \hline
	\textbf{Location} & Motherboard, connected to the CPU by a bus.
	\\ \hline
\end{longtabu}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/main-memory.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Main memory}
  \end{minipage}}
\end{figure}

Main memory is typically a random-access memory (RAM) device. These devices allow data items to be read from or written to in almost the same amount of time, irrespective of the physical location of the data.


\section{Secondary memory}

\section*{Definition}

\textbf{Secondary memory} is a non-volatile and persistent store of data, which is used for items such as user files, programs and the operating system.


\section*{Magnetic -- Hard-Disk Drive (HDD)}

\subsection*{Description}

A \textbf{Hard-Disk Drive (HDD)} contains rotating platters which are coated with magnetic material. This contains ferrous particles, containing iron, which are polarised to become either a north or south state; these states can correspond to either a 0 or a 1.

The platters spin at speeds of up to 10,000 revolutions per minute (RPM) and a drive head moves across the platters to access different tracks and sectors. Data is read from or written to the platters as it passes under the drive head. When no operations are being performed, the drive head is parked to the side of the platters to prevent damage from movement.

There may be several platters and several drive heads.

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & xxx’GB and x’TB.
	\\ \hline
	\textbf{Speed} & Medium.
	\\ \hline
	\textbf{Purpose} & Consumer desktop computer system secondary storage.
	\\ \hline
	\textbf{Reliability} & Prone to drop damage as it has moving parts and magnetic fields.
	\\ \hline
\end{longtabu}

\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Large storage capacity}. & \textbf{Relatively slow read and write speeds} because the disk head must physically move to the location of the data on the platter.
	\\ \hline
	\textbf{Affordable large capacities}, HDDs are available in large storage capacities at relatively low prices. & \textbf{Can be loud} because there are moving parts, such as the platters and disk head, which generate noise.
	\\ \hline
	& \textbf{Low reliability} because they are prone to drop damage, due to their moving parts, magnetic fields.
	\\ \hline
	& \textbf{Relatively large form factor} since there must be room to enclose the platters and disk heads.
	\\ \hline
\end{longtabu}


\section*{Magnetic -- Magnetic tape}

\subsection*{Description}

A \textbf{magnetic tape} is a reel of tape which is coated with a magnetic material. This contains ferrous particles, containing iron, which are polarised to become either a north or south state; these states can represent either a 1 or a 0.

The data is accessed using serial access; this is where a tape reader starts at the beginning of the tape and “fast forwards” to the portion of the tape containing the required data.

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & xxx’GB and x’TB.
	\\ \hline
	\textbf{Speed} & Slow.
	\\ \hline
	\textbf{Purpose} & Server backup storage.
	\\ \hline
	\textbf{Reliability} & Prone to magnetic fields.
	\\ \hline
\end{longtabu}


\newpage

\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Large storage capacity}. & \textbf{Relatively slow read and write speeds} because it uses serial data access.
	\\ \hline
	\textbf{Affordable large capacities}, magnetic tapes are available in high capacities at relatively low prices & \textbf{Low reliability} because they are prone to magnetic fields.
	\\ \hline
	& \textbf{Requires specialist equipment} to read the data on the tape, known as a tape reader.
	\\ \hline
\end{longtabu}


\section*{Flash -- Solid-State Drive (SSD)}

\subsection*{Description}

A \textbf{Solid-State Drive (SSD)} contains millions of NAND flash memory cells and a controller which manages pages and blocks of memory.

Each NAND flash memory cell delivers a current along the bit and word lines to activate the flow of electrons from the source towards the drain. The current on the word line is strong enough to push a few electrons across an insulated oxide layer into a floating gate. The charge in the flowing gate is measured: if there is some charge, where there are some electrons flowing, a 1 is represented; and if there is no charge, where there are no electrons flowing, a 0 is represented.
\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & xx’GB and xxx’GB.
	\\ \hline
	\textbf{Speed} & Very fast.
	\\ \hline
	\textbf{Purpose} & Portable device secondary storage, such as smartphones and laptops.
	\\ \hline
	\textbf{Reliability} & Less prone to drop damage as there are no moving parts, limited write cycles before damage.
	\\ \hline
\end{longtabu}

Flash drives and SD cards also use solid-state technologies. They are often used for portable storage; for example, flash drives may be used for transferring documents and SD cards may be used to storage images in a camera.


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Fast read and write speeds} because the data can be accessed directly on the drive using electrical currents. & \textbf{Expensive large capacities}, SSDs are more expensive than other storage options.
	\\ \hline
	\textbf{Available in different form factors}, such as USB memory sticks and SD cards. & \textbf{Low durability} because they have a finite number of read and write operations which can be performed before the performance of the drive beings to downgrade due the discharge of its electrons.
	\\ \hline
	\textbf{High reliability} because there are no moving parts. &
	\\ \hline
	\textbf{Silent operation} because there are no moving parts. &
	\\ \hline
\end{longtabu}


\section*{Optical -- Optical disk}

\subsection*{Description -- Optical disk}

An \textbf{optical disk} works by using:
\begin{itemize}
	\item a high-powered laser to change the properties of its surface to make them less reflective, by a process called “burning”; and
	\item a low-powered laser to read the disk by shining light onto the surface and a sensor is used to measure the amount of light that is reflected back.
\end{itemize}

There are multiple types of optical disks, including:
\begin{itemize}
	\item CD-ROM;
	\item CD-RW;
	\item DVD-RW; and
	\item Bluray.
\end{itemize}

\subsection*{Description -- CD-ROM}

A \textbf{CD-ROM (read only Compact Disk)} is pressed during is manufacture and has pits, where the surface has been depressed, and lands, where the surface has not been depressed.

When the low-powered laser is shone on the surface:
\begin{itemize}
	\item the start or end of a pit, the light is scattered and not reflected very well –- this is used to represent a 0; and
	\item a land, the light is not scattered and reflected normally -– this is used to represent a 1.
\end{itemize}
\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & xxx'MB.
	\\ \hline
	\textbf{Speed} & Slow.
	\\ \hline
	\textbf{Purpose} & Commercial music distribution.
	\\ \hline
	\textbf{Reliability} & Prone to scratches and cracks.
	\\ \hline
\end{longtabu}


\subsection*{Description -- CD-RW}

A \textbf{CD-RW (re-writable Compact Disk)} uses a laser and a magnet to heat a spot on the disk. When the spot is heated the magnetic orientation is changed to represent a 0 or a 1 before the magnet is cooled.
\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & xxx'MB.
	\\ \hline
	\textbf{Speed} & Slow.
	\\ \hline
	\textbf{Purpose} & Small file storage such as documents.
	\\ \hline
	\textbf{Reliability} & Prone to scratches and cracks.
	\\ \hline
\end{longtabu}


\subsection*{Description -- DVD-RW}

A \textbf{DVD-RW (re-writable Digital Versatile Disc)} uses a phase changed alloy that can change between amorphous and crystalline states by changing the power of the laser beam.
\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & x'GB.
	\\ \hline
	\textbf{Speed} & Slow.
	\\ \hline
	\textbf{Purpose} & Standard definition videos.
	\\ \hline
	\textbf{Reliability} & Prone to scratches and cracks.
	\\ \hline
\end{longtabu}


\subsection*{Description -- Blu-Ray}

A \textbf{Blu-Ray} disk has a higher capacity than a CD-ROM because the laser used has a shorter wavelength which creates smaller pits and lands and therefore, a greater number of pits and lands can be present on the same surface area.

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & xx'GB.
	\\ \hline
	\textbf{Speed} & Slow.
	\\ \hline
	\textbf{Purpose} & High definition videos.
	\\ \hline
	\textbf{Reliability} & Prone to scratches and cracks.
	\\ \hline
\end{longtabu}


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Relatively portable} because they can be carried in a disk case. & \textbf{Relatively slow read and write speeds} because the disk must spin in the optical drive to read the data.
	\\ \hline
	\textbf{Immune to magnetic fields} meaning that the close proximity of a magnet is not going to corrupt data. & \textbf{Low reliability} because they are prone to scratches and cracks.
	\\ \hline
\end{longtabu}


\newpage

\section{Read-only memory}

\section*{Properties}

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] |}
    \hline
    \textbf{Size} & Medium (MB/GB).
	\\ \hline
	\textbf{Speed} & Fast.
	\\ \hline
	\textbf{Purpose} & Used in the system boot process and, in some cases, stores the operating system in computer systems where the software is not updated.
	\\ \hline
	\textbf{Reliability} & Motherboard.
	\\ \hline
\end{longtabu}


\section*{Use in the system boot process}

A \textbf{Basic Input/Output System (BIOS)} is a set of instructions which control the boot process of a computer system and the communication between the operating system and peripherals.

A \textbf{peripheral} is a piece of hardware outside a computer system that is not required for the computer system to operate.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{0.3935\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	\includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/system-boot-process.png}
  \end{minipage}
  \begin{minipage}{0.6\dimexpr \textwidth-2\fboxsep-2\fboxrule}
  	\centering
  	The motherboard BIOS initialises registers and power management.
    
	$\downarrow$
	
	The motherboard BIOS performs a self-diagnostic test, known as a Power-On Safe Test (POST).
	
	$\downarrow$
	
	The motherboard BIOS boots the BIOS for all subsidiary boards and begins communications with basic peripherals.
	
	$\downarrow$
	
	The motherboard BIOS determines which non-volatile storage device contains the operating system (OS).
	
	$\downarrow$
	
	The motherboard BIOS initiates the bootstrapping sequence where the secondary bootloader, such as GRUB, LILO or NTLDR etc., is copied to RAM.
	
	$\downarrow$
	
	The secondary bootloader waits for a few seconds to allow the user to make a choice on the operating system (OS) to be launched.
	
	$\downarrow$
	
	The secondary bootloader loads the chosen operating system (OS) to RAM and relinquishes control.
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{System boot process}
  \end{minipage}}
\end{figure}


\section{Concept and aim of memory management}

\section*{Concept}

Processes share physical memory, as well as the CPU. Main memory (RAM) is one of the most important resources in a computer system as:
\begin{itemize}
	\item data and instructions are fetched from RAM in to the CPU for execution; and
	\item memory can store several running processes at once.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/main-memory-and-non-volatile-memory.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Main memory and non-volatile memory}
  \end{minipage}}
\end{figure}

As seen in the diagram above, RAM can contain the data and instructions for multiple processes. These are loaded in to RAM from non-volatile memory, such as a hard-disk drive (HDD).


\section*{Aim}

Aims of memory management include:
\begin{itemize}
	\item providing the memory space for concurrent processes;
	\item taking advantage of the locality of reference, which is the tendency of a CPU to access the same set of memory locations repetitively over a short period of time, by estimating the data and/or instructions to be used next and transfer them to the most effective place in the memory hierarchy pyramid;
	\item protect processes from one another;
	\item relocated memory to new processes; and
	\item make the addressing of memory space transparent by providing memory abstraction.
\end{itemize}


\section{Overview of memory abstraction}

\section*{Definition}

\textbf{Memory abstraction} provides an abstraction layer between the program execution and the memory that provides a different "view" of a memory location depending on the execution context in which the memory access is made. This is achieved by creating an “abstract memory” to allow for co-existence in physical memory.


\section*{Computer system with no memory abstraction}

Early mainframe computers had no memory abstraction and every program had access to physical memory.

The memory model presented to the programmer was a set of addresses from zero (0) to max, in which each address corresponds to a cell containing some number of bits.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/no-memory-abstraction.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Organising memory with an operating system and one user process}
  \end{minipage}}
\end{figure}

The diagram above shows three different ways of organising memory with an operating system and one user process.

\begin{longtabu} to \textwidth {| X[1,l] | X[6,l] | X[6,l] | }
    \hline
    \textbf{Model} & \textbf{Organisation} & \textbf{Uses} 
	\\ \hline
	(a) & The operating system may be at the bottom of memory in RAM.
	& This model was formerly used on mainframes and minicomputers but is rarely used any more.
	\\ \hline
	(b) & The operating system may be in ROM at the top of memory.
	& This model is used on some handheld computers and embedded systems. 
	\\ \hline
	(c) & The device drivers may be at the top of memory in ROM and the operating system may be in RAM at the bottom of memory.
	& This model was formerly used by early personal computers, such as those running MS-DOS, where part of the operating system (OS) was stored in BIOS.
	\\ \hline
\end{longtabu}

These models refer to fixed memory addresses and therefore prevent more than one process running at a time.


\section{Memory abstraction - Physical address}

\section*{Definition}

An \textbf{address space} is a set of addresses that a process can use to reference memory.

A \textbf{physical address} (or \textbf{memory address}) identifies a physical location of required data in a memory.

\textbf{Logical address space} is the set of all physical addresses corresponding to the logical addresses in a logical address space.


\section*{Referencing physical memory}

It is possible to reference memory by using the physical address locations.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/referencing-physical-memory.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Referencing physical memory}
  \end{minipage}}
\end{figure}


\section*{Drawbacks}

However, this is not ideal as:
\begin{itemize}
	\item user programs can address physical memory directly and trash the OS intentionally/accidentally, i.e. models (a) and (c); and
	\item it is difficult to have multiple programs running at once (via context switch).
\end{itemize}

For these reasons, users should not be able to reference physical memory directly.


\newpage

\section{Memory abstraction - Logical address}

\section*{Definition}

An \textbf{address space} is a set of addresses that a process can use to reference memory.

A \textbf{logical address} (or \textbf{program address}) is generated by the CPU while a program is running. The logical address is virtual address as it does not exist physically, therefore, it is also known as \textbf{virtual address}. This address is used as a reference to access the physical memory location by CPU.

\textbf{Logical address space} is the set of all logical addresses generated by a program’s perspective.


\section*{Using logical address spaces}

Programmers can refer to their own address space, the logical address space for a given program.

It is possible for the same logical address, as seen by two different processes, to correspond to different physical addresses. It is important that a distinction is made between the two physical addresses.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/address-spaces.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Logical address spaces}
  \end{minipage}}
\end{figure}

When a process is loading, the \textbf{loader} is responsible for transferring the program from mass storage to main memory for execution.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/loader.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loader}
  \end{minipage}}
\end{figure}

It is not possible to determine where the program is loaded in physical memory as its location depends on the current contents of memory. As a result, the program's code cannot refer to fixed memory addresses.

As discovered before, machine instructions should not directly access the physical address space and therefore logical addresses are used. These must be converted to physical addresses by the Memory Management Unit (MMU).


\section{Memory Management Unit (MMU)}

\section*{Definition}

The \textbf{Memory Management Unit (MMU)} is responsible for the logical-physical conversion. This is achieved by using registers to record the location of the partition in order to map the logical addresses to the correct physical addresses.


\newpage

\section*{Base and limit registers}

The \textbf{base register} stores the start address of the partition.

The \textbf{limit register} stores the length of the partition.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{\textheight}]{images/chapter-5/base-and-limit-registers.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Base and limit registers between CPU and RAM}
  \end{minipage}}
\end{figure}


\section*{Memory protection and relocation}

\subsection*{Definitions}

\begin{itemize}
	\item \textbf{Relocation} -- The base register value is added to the logical address in order to map the logical address to a physical address.
	\item \textbf{Protection} -- Logical addresses that are greater than the limit register value should point to an invalid memory location. This check ensures that the logical address is within the range of the partition in order to ensure that a process is only accessing its own logical address space.
\end{itemize}


\subsection*{How it works}

The address part of a given machine instruction is used as an offset from the base address.

For example, a machine instruction may have
\begin{itemize}
	\item a base address of \texttt{101}; and
	\item the instruction \texttt{JMP}.
\end{itemize}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/memory-protection-and-relocation.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Base and limit registers between CPU and RAM}
  \end{minipage}}
\end{figure}

The operating system (OS) would be responsible for allowing the process to access the memory location desired by the process after the \texttt{JMP} instruction.

The \texttt{JMP 5} shows a logical address of \texttt{5}, while the physical address has a base of \texttt{101} and therefore the resulting physical address is \texttt{106}.

In this scenario, if the machine instruction contained \texttt{JMP 100} instead, there would be an invalid memory location error. This is because the \texttt{JMP 100} instruction would result in a physical address of \texttt{201}. This violates the logical address limit of \texttt{100} and the physical address limit of \texttt{201} and therefore this error must be thrown for protection.



\section{Memory partitioning}

\section*{Definition}

\textbf{Memory partitioning} is the system by which the memory of a computer system is divided into sections for use by the resident programs.

This may be achieved by fixed partitioned memory or variable partitioned memory.


\section*{Fixed partitioned memory}

\subsection*{How it works}

Memory is divided in to several partitions of fixed sizes. The partitions may be different sizes from one another, but remain at the same size once created.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{6cm}]{images/chapter-5/fixed-partitioned-memory.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Variable partitioned memory}
  \end{minipage}}
\end{figure}

As shown above, each process (\texttt{A}, \texttt{B} and \texttt{C}) has its own partition.


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Multiprogramming}, as it is compatible with process co-existence in memory. &
	\textbf{Restricted} as there is a fixed number of possible simultaneous processes.
	\\ \hline
	\textbf{Easy to implement}. &
	\textbf{Internal fragmentation}, as each partition has unused space.
	\\ \hline
	\textbf{Allows for fast context switching}. & \textbf{Inefficient space usage} due to internal fragmentation.
	\\ \hline
	& \textbf{Issues may occur} if a process is too large for any partition.
	\\ \hline
\end{longtabu}



\section*{Variable partitioned memory}

\subsection*{How it works}

Each process is allocated an exact size of memory space. Processes are loaded in to contiguous memory slots until memory is full.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{6cm}]{images/chapter-5/variable-partitioned-memory.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Variable partitioned memory}
  \end{minipage}}
\end{figure}

As shown above, when processes \texttt{A} and \texttt{B} terminate, their memory space is deallocated.


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{No internal fragmentation}. & \textbf{Assumes that the memory manager knows how much memory a process requires}.
	\\ \hline
	\textbf{Efficient space usage} as when a process terminates, the space it once occupied in memory is freed up. & \textbf{External fragmentation may occur}, where "holes" outside partitions are introduced.
	\\ \hline
	\textbf{Adjacent fragmentation can be merged}. &
	\\ \hline
	\textbf{The number of parallel processes is not fixed}. &
	\\ \hline
\end{longtabu}


\subsection*{Compaction}

Reducing external fragmentation is achieved by compaction.

This is a process whereby processes are physically moved to close the "holes" created by the deallocation of memory that once belonged to processes.

However, this process has a heavy overhead causing slowdowns and therefore, is not commonly performed.


\subsection*{Dealing with processes of varying size}

So far, it is been assumed that processes have a fixed size and that the operating system (OS) allocates that memory.

However, it is possible that some processes may try to grow their memory allocation, such as increasing the size of an array.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/varying-process-sizes.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Varying process sizes}
  \end{minipage}}
\end{figure}

As shown in the diagram above, if a hole is adjacent to the process, it can be allocated to the process to allow the process to grow in to that hole.

Otherwise, it is necessary to allocate more memory in a different physical location. If memory is full, swapping may occur or the process needs to be suspended.


\section{Swapping}

\section*{Definition}

\textbf{Swapping} is a memory reclamation method wherein memory contents not currently in use are swapped to a disk to make the memory available for other applications or processes.


\section*{Why is swapping required?}

Memory is not an infinite resource, as shown in the memory hierarchy (page n). In practice, the total amount of RAM required by all running processes is often larger than the amount available in the computer system.

Idle processes are typically stored on secondary memory as to provide access to more primary memory for processes that are currently in use.

Memory allocations change as processes are loaded and unloaded from memory.


\section*{How it works}

Swapping shows a simple strategy of loading each process in to memory in its entirety, executing the process for an amount of time and then returning it to secondary memory. This is a similar concept to context switching.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/swapping.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Swapping}
  \end{minipage}}
\end{figure}

However, swapping adds a layer of complexity as the operating system must now manage free space.


\section{Managing free space}

When memory is assigned dynamically via swapping, the operating system must manage it. In general terms, there are two ways to keep track of memory usage: bitmaps and free lists.


\section*{Bitmaps}

\subsection*{How it works}

Memory is divided into allocation units as small as a few words and as large as several kilobytes.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/bitmaps.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Using bitmaps to manage free space}
  \end{minipage}}
\end{figure}

As shown above, corresponding to each allocation unit is a bit in the bitmap, which is:
\begin{itemize}
	\item zero (\texttt{0}) if the unit is free; and
	\item one (\texttt{1}) if the unit is occupied.
\end{itemize}


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Fast} as the bitmap array can be accessed directly and the status of the allocation unit can be determined. & \textbf{Maintenance overhead} as the status of each allocation unit must be maintained in the bitmap. 
	\\ \hline
\end{longtabu}


\newpage

\section*{Free lists}

\subsection*{How it works}

A list of processes, denoted as \texttt{P}, and holes, denoted as \texttt {H}, are kept in a list.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/free-lists.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Using free lists to manage free space}
  \end{minipage}}
\end{figure}

In the free list example shown above, there is the following sequence of processes \texttt{P} and holes \texttt{H} in memory:
\begin{itemize}
	\item a process (\texttt{P}) starting at \texttt{0} and occupying \texttt{5} spaces;
	\item a hole (\texttt{H}) starting at \texttt{5} and occupying \texttt{3} spaces;
	\item a process (\texttt{P}) starting at \texttt{8} and occupying \texttt{6} spaces;
	\item a process (\texttt{P}) starting at \texttt{14} and occupying \texttt{4} spaces;
	\item a hole (\texttt{H}) starting at \texttt{18} and occupying \texttt{2} spaces;
	\item a process (\texttt{P}) starting at \texttt{20} and occupying \texttt{6} spaces;
	\item a process (\texttt{P}) starting at \texttt{26} and occupying \texttt{3} spaces; and
	\item a hole (\texttt{H}) starting at \texttt{29} and occupying \texttt{3} spaces.
\end{itemize}

Several algorithms, known as placement policies, can be used to allocate memory for new processes.


\subsection*{Evaluation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{More compact} than using a bitmap as, for example, a sequence of occupied units can be expressed as [P, 0, 5] rather than 11111. & \textbf{More complex} as it is more difficult to manage and placement policies are required.
	\\ \hline
\end{longtabu}


\section*{Placement policies}

\subsection*{First fit}

In first fit, the memory manager scans along the list of segments until it finds a hole that is large enough.

The hole is then broken up into two pieces, one for the process and one for the unused memory, except in the statistically unlikely case of an exact fit.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-first-fit-2.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using first fit with size \texttt{2KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-first-fit-4.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using first fit with size \texttt{4KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-first-fit-1.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using first fit with size \texttt{1KB}.}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Fast} because it searches as little as possible. &
	\textbf{May generate more holes}
	\\ \hline
\end{longtabu}


\newpage

\subsection*{Next fit}

Next fit is a variation of the first fit policy. It works the same way as first fit, except that it keeps track of where it is whenever it finds a suitable hole.

The next time it is called to find a hole, it starts searching the list from the place where it left off last time, rather than the beginning of the list.

This policy was designed to speed up searching by skipping potential tiny holes that cannot fit a process. However, simulations show that next fit gives slightly worse performance than first fit.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-next-fit-2.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using next fit with size \texttt{2KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-next-fit-4.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using next fit with size \texttt{4KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-next-fit-1.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using next fit with size \texttt{1KB}.}
  \end{minipage}}
\end{figure}


\newpage

\subsection*{Best fit}

In best fit, the memory manager searches the entire list, from beginning to end, and finds the hole that is closest to the actual size required rather than breaking up a larger hole that may be required later.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-best-fit-2.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using best fit with size \texttt{2KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-best-fit-4.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using best fit with size \texttt{4KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-best-fit-1.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using best fit with size \texttt{1KB}.}
  \end{minipage}}
\end{figure}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{May reduce memory wastage} by using better suited holes for processes. &
	\textbf{May increase memory wastage} as it may generate many tiny holes that are too small to be used by any process. This could be worse than first fit and next fit as they generate larger holes on average that could be used by other processes.
	\\ \hline
	& \textbf{Slower than first fit and next fit} as it requires a search to be completed on the entire list.
	\\ \hline
\end{longtabu}


\newpage

\subsection*{Worst fit}

Worst fit is the opposite of the best fit policy. It always finds the largest available hole, so that the new hole will be big enough to be useful.

This policy was designed to reduce the number of tiny and unusable holes generated by the best fit policy. However, simulations show that it is not very successful.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-worst-fit-2.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using worst fit with size \texttt{2KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-worst-fit-4.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using worst fit with size \texttt{4KB}.}
  \end{minipage}}
\end{figure}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-5/placement-policies-memory-worst-fit-1.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading a process using worst fit with size \texttt{1KB}.}
  \end{minipage}}
\end{figure}


\subsection*{Quick fit}

In quick fit, the memory manager maintains a table of separate lists for some of the more common sizes requested.

For example, there may be a list for large holes and a list for small holes.

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Extremely fast} as the lists can be used to quickly find appropriate holes. &
	\textbf{Overhead} as the lists must be maintained.
	\\ \hline
\end{longtabu}


\chapter{Virtual memory}

\section{Introduction}

\section*{Definition}

\textbf{Virtual memory} is a memory management technique that provides an idealised abstraction of the storage resources that are actually available on a given machine.


\section*{How it works}

Virtual memory involves the use of a partition on a computer system’s secondary storage device which acts as a form of main memory for the temporary store of data and instructions used in processing by the CPU; this is required when main memory becomes full and is present to prevent crashing.

Parts of processes are stored on secondary storage and loaded in to main memory when required.

This creates the illusion to users of a very large main memory.


\section*{Virtual memory and swapping}

While swapping allows multiple processes to run whose total size is larger than overall RAM size, virtual memory additionally allows a single process to run whose size is larger than RAM size.

Virtual memory is implemented using paging and segmentation.


\section{Paging}

\section*{Definition}

\textbf{Paging} is a memory management mechanism that allows the physical address space of a process to be non-contiguous.


\section*{Frames and pages}

Physical memory is divided in to blocks of equal sizes called \textbf{frames}.

In a similar fashion, a process is divided in to blocks of the same size, called \textbf{pages}.

The pages from the processes are loaded in to the available frames in physical memory.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{10cm}]{images/chapter-6/paging.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Loading process pages in to physical memory frames.}
  \end{minipage}}
\end{figure}

In the diagram above, there are four processes:
\begin{itemize}
	\item process \texttt{A} which has four pages;
	\item process \texttt{B} which has two pages;
	\item process \texttt{C} which has three pages; and
	\item process \texttt{D} which has four pages.
\end{itemize}

In the first instance, memory is allocated to processes \texttt{A}-\texttt{C}. Subsequently, process \texttt{B} terminates and its pages are released from the frames.

Later, process \texttt{D} starts. This process has four pages and is therefore split across the two frames available between processes \texttt{A} and \texttt{C}, and after process \texttt{C}.

This is a good solution to address external fragmentation.


\section*{Page table}

\subsection*{Definition}

A \textbf{page table} is responsible for mapping virtual pages in to page frames when using paging.


\subsection*{Fields}

The layout of a page table is highly machine dependent. However, important common fields of a page table entry include:
\begin{itemize}
	\item page frame -- the most important field that outputs the number of the frame;
	\item present -- records whether the page is present in main memory or secondary memory;
	\item modified (or dirty bit) -- records whether the page has been modified since its last loading, if true then it must be copied back to the disk to be saved;
	\item protection -- includes what kind of access is permitted, read/write/execute; and
	\item referenced -- set by the operating system (OS) when the page is used.
\end{itemize}


\subsection*{Mapping logical program addresses to physical memory addresses}

Each logical address is formed as \texttt{(p,d)} where
\begin{itemize}
	\item \texttt{p} is the process page number; and
	\item \texttt{d} is the displacement within that page (offset).
\end{itemize}
\texttt{p} occupies 4 bits and while \texttt{d} occupies 12 bits.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/logical-program-address.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Logical program address in paging.}
  \end{minipage}}
\end{figure}

In addition, each process has a page table, which records the memory page frame number for each process page.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/logical-program-address-and-page-table.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Logical program address and respective page table.}
  \end{minipage}}
\end{figure}

The implementation is performed by the hardware, as such the Memory Management Unit (MMU) is responsible for mapping the logical addresses to physical addresses.

Given a 16-bit program address \texttt{0100 0000 0110 0100}, it can be deduced that:
\begin{equation*}
	\begin{aligned}
		\text{p} & = & 0100_{2} & = & 4_{10} \\
		\text{d} & = & 0000\;0110\;0100_{2} & = & 100_{10}
	\end{aligned}
\end{equation*}

The process page number (\texttt{p}) provides an index to a location in the page table.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/using-p-as-index-to-page-table.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Using \texttt{p} as an index to the page table.}
  \end{minipage}}
\end{figure}

The value at index \texttt{4} in the page table can then be used as the base (\texttt{b}) for the physical memory address.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/page-table-value-to-base-value.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Using the value at index \texttt{4} as the base (\texttt{b}).}
  \end{minipage}}
\end{figure}

The displacement (\texttt{d}) from the logical program address can then be used to complete the physical memory address.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/using-displacement-value.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Using the displacement value (d) to complete the physical memory address.}
  \end{minipage}}
\end{figure}

This can also be shown by performing the following operations:
\begin{equation*}
	\begin{aligned}
		\text{physical memory address} & = \text{page table value at index p} + \text{displacement value (d)} \\
		\text{physical memory address} & = 1100\;0000\;0000\;0000 + 0000\;0110\;0100 \\
		\text{physical memory address} & = 1100\;0000\;0110\;0100_{2} = 104_{10}
	\end{aligned}
\end{equation*}


\section*{Page faults}

\subsection*{Definition}

A \textbf{page fault} is a type of exception raised by computer hardware when a running program accesses a memory page that is not currently mapped by the memory management unit (MMU) into the virtual address space of a process.

This means that a specific part of an executing process is not in main memory at the moment it is required and therefore the CPU is not able to access this part of the process.


\subsection*{Page fault handling}

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    When a specific part of an executing process is not in main memory when required, a page fault occurs.
    
	$\downarrow$
	
	The OS reads out hardware registers to determine which virtual address caused the fault.
	
	$\downarrow$
	
	The OS computes which page is needed and locates that page on disk.
	
	$\downarrow$
	
	The OS selects an existing available page frame.
	
	$\downarrow$
	
	The OS checks if that page frame is modified by inspecting the modified field.
	
	$\downarrow$
	
	If the page frame has been modified, the OS writes the contents of the page frame back to the disk.
	
	$\downarrow$
	
	The OS fetches a new page from the disk and replaces the old page in the page frame. This is known as page replacement.
	
	$\downarrow$
	
	The OS updates the mappings and restarts the trapped instruction by:
	\begin{itemize}
		\item marking the virtual page as unmapped by changing the present bit in the page table; and
		\item updating the virtual page address with new translation to physical memory.
	\end{itemize}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Page fault handling process}
  \end{minipage}}
\end{figure}


When a process exits, the operating system must release its page table, its pages, and the disk space that the pages occupy when they are on disk. If some of the pages are shared with other processes, the pages in memory and on disk can be released only when the last process using them has terminated.


\section*{Page replacement}

\subsection*{Definition}

\textbf{Page replacement} is required during page fault handling when the OS fetches a new page from the disk and replaces the old page in the page frame.

\textbf{Page replacement algorithms} decide which pages to page out, sometimes called swap out, or write to disk, when a page of memory needs to be allocated.


\subsection*{Objective}

Page replacement algorithms aim to decided which pages are to be removed from RAM and placed in mass storage such that there are minimal overheads.

This allows thrashing to be avoided, where the CPU is spending more time swapping pages than actually executing a process.

As such, it must be considered that:
\begin{itemize}
	\item modified pages must first be saved whereas unmodified pages are just overwritten; and
	\item it is preferable to not replace an often used page in and out of main memory.
\end{itemize}

These algorithms use information (bits) from the page table.


\subsection*{Optimal page replacement}

The \textbf{optimal page replacement algorithm} replaces the page that will not be needed for the longest time in the future.

This is not feasible because:
\begin{itemize}
	\item it is impossible to know the future of a program; and
	\item it is impossible to know when a given page will be needed next.
\end{itemize}

However, this is useful for benchmarking page replacement algorithms a posteriori (i.e. "what if").


\subsection*{Not recently used page replacement}

The \textbf{not recently used page replace algorithm} uses the reference and modified bits from the page table to collect useful page usage statistics.

Pages are classified based on the contents of their reference and modified bits in the page table.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {|X[0.5,l]|X[0.75,l]|X[0.75,l]|X[2,l]|}
	    \hline
	    \textbf{Class} & \textbf{Reference bit}
	    & \textbf{Modified bit} & \textbf{Meaning}
	    \\ \hline
		\texttt{Class 0} & 0 & 1 & Not referenced and not modified.
		\\ \hline
		\texttt{Class 1} & 0 & 1 & Not referenced and modified.
		\\ \hline
		\texttt{Class 2} & 1 & 0 & Referenced and not modified.
		\\ \hline
		\texttt{Class 3} & 1 & 1 & Referenced and modified.
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Page classification}
  \end{minipage}}
\end{figure}

Based on the page classifications, the algorithm removes a page from the lowest numbered non-empty class. For example, should pages exist in \texttt{Class 1}, \texttt{Class 2} and \texttt{Class 3} but not \texttt{Class 0}, then a page would be removed from \texttt{Class 1}.

A timer interrupt clears the reference bit to distinguish between those pages that have been recently referenced and those which have not been referenced for a given amount of time.

\newpage

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Very low overhead}. & \textbf{Not optimal} when compared to the optimal page replacement algorithm.
	\\ \hline
	\textbf{Easy to implement}. &
	\\ \hline
\end{longtabu}


\subsection*{FIFO page replacement}

In the \textbf{First In, First Out (FIFO) page replacement algorithm}, main memory maintains a list of all pages currently stored in main memory. In which,
\begin{itemize}
	\item the most recently arrived page is located at the tail; and
	\item the least recently arrived page is located at the head.
\end{itemize}

When page replacement occurs, the page at the head is removed and the new page is added to the tail of the list such that the oldest page is removed.

However, this algorithm is rarely used as the oldest page may still be useful.


\subsection*{Second chance page replacement}

The \textbf{second chance page replacement algorithm} is a variation of the FIFO page replacement algorithm. It attempts to avoid the problem of replacing a heavily used page.

The algorithm checks the reference bit of the oldest page first and performs actions based on the page's state deduced from the reference bit.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {|X[0.6,l]|X[0.75,l]|X[2,l]|}
	    \hline
	    \textbf{Reference bit} & \textbf{Page's state}
	    & \textbf{Actions taken}
	    \\ \hline
		0 & Old and unused. &
		The page is replaced in the list, in the same manner as the FIFO page replacement algorithm.
		\\ \hline
		1 & Old but used. &
		The page is placed at the end of the list of pages, the load time resets as though it has just arrived in memory and the search continues to the next page.
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Page classification for the second chance page replacement algorithm.}
  \end{minipage}}
\end{figure}

As shown in the figure above, the second change page replacement algorithm factors in the use of a page as well as its age.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/second-change-page-replacement-a.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Pages shorted in FIFO order.}
  \end{minipage}}
\end{figure}

The figure above shows the pages sorted in FIFO order, with the most recently arrived page at the head of the list of pages and the least recently arrived page at the tail of the list of pages.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/second-change-page-replacement-b.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{"Second chance" for page \texttt{A}.}
  \end{minipage}}
\end{figure}

The figure above shows a "second chance" for page \texttt{A}. If a page fault was to occur at time \texttt{20} and page \texttt{A} has a reference bit of 1, the loads times are updated such that it appears that page \texttt{A} has just arrived in memory.

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Improvement over the FIFO page replacement algorithm} as avoids removing old but useful pages. & \textbf{Not optimal} when compared to the optimal page replacement algorithm as unnecessarily moves pages around the list.
	\\ \hline
\end{longtabu}


\subsection*{Clock page replacement}

The \textbf{clock page replacement algorithm} is also a variation fo the FIFO page replacement algorithm and is similar to the second chance page replacement algorithm but maintains the pages on a circular list.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/clock-page-replacement.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Clock page replacement algorithm.}
  \end{minipage}}
\end{figure}

As shown in the figure above, the pages are kept in a circular list in memory, where the hand points to the oldest page.

When a page fault occurs, the page being pointed to by the hand and performs actions based on the page's state deduced from the reference bit.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \begin{longtabu} to \textwidth {|X[0.6,l]|X[0.75,l]|X[2,l]|}
	    \hline
	    \textbf{Reference bit} & \textbf{Page state}
	    & \textbf{Actions taken}
	    \\ \hline
		0 & Old and unused. &
		The page is replaced in the clock in the same manner as the FIFO page replacement algorithm, and the hand is advanced to the next page.
		\\ \hline
		1 & Old but used. &
		The reference bit for the page is cleared and the hand is advanced to the next page. This is repeated until a page is found with a reference bit of 0.
		\\ \hline
	\end{longtabu}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Page classification for the clock page replacement algorithm.}
  \end{minipage}}
\end{figure}

This algorithm is realistic as it avoids the unnecessary movement of pages as seen in the second chance page replacement algorithm.


\subsection*{Least recently used page replacement}

The \textbf{least recently use page replacement algorithm} is based on the ideas that:
\begin{itemize}
	\item pages that have been heavily used in the last few instructions will probably be heavily used again soon; and
	\item pages that have not been used for ages will probably remain unused for a long time.
\end{itemize}

It is necessary for a linked list of all pages to be maintained in memory with:
\begin{itemize}
	\item the most recently used page at the front; and
	\item the least recently used page at the back.
\end{itemize}

As such, the algorithm swaps out pages that have been unused for the longest time.

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	& \textbf{Requires time-consuming maintenance of the linked list} as the list must be updated on every memory reference such that referenced pages are moved to the front.
	\\ \hline
\end{longtabu}


\subsection*{Not frequently used page replacement}

The \textbf{not frequently used page replacement algorithm} keeps track of how often a page is used.

A counter is associated with each page and is initially set to 0. At each clock interrupt, the OS will scan all pages in memory. For each page, the reference bit will be added to its associated counter, such that:
\begin{itemize}
	\item if the reference bit is 0, the counter will remain the same; and
	\item if the reference bit is 1, the counter will be incremented.
\end{itemize}

This means that counters can be used to track how often each page has been referenced.

When a page fault occurs, the page with the lowest counter is chosen for replacement.


\section*{Evaluation of paging}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Almost full utilisation of physical memory}. &
	\textbf{Some internal fragmentation} as a process may not use memory in multiples of a page; usually the last page may not use the entire page size.
	\\ \hline
	\textbf{Can execute programs that have address space larger than physical memory}. &
	\textbf{Tuning the page size is tricky} as
	\begin{itemize}
		\item a smaller page size leads to less internal fragmentation but more pages are required and therefore the page tables will be larger; and
		\item a larger page size leads to more unused programs to be loaded in to memory but less pages are requires and therefore the page tables will be smaller.
	\end{itemize}
	\\ \hline
	\textbf{No external fragmentation}. & 
	\textbf{Large memory consumption} as one page table for each process may consume large amounts of memory.
	\\ \hline
	& \textbf{Does not support the logical divisions of programs} as page sizes are fixed and not based on the actual size of programs.
	\\ \hline
\end{longtabu}


\section{Segmentation}

\section*{Definition}

\textbf{Segmentation} is a memory management scheme that supports the logical user-view of programs.


\section*{How it works}

Each program is split in to variable chunks called segments according to the program's logical structure.

Different compilers for programs may split programs in to different segments.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/segmentation.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Program segments from a C compiler.}
  \end{minipage}}
\end{figure}

As shown in the figure above, a C compiler may generate four segments with different sizes:
\begin{itemize}
	\item text segment (main code) and libraries;
	\item data segment;
	\item the stack; and
	\item the heap.
\end{itemize}

The stack and heap are of dynamic size, as they may shrink and grow over the course of the program's lifetime.

Memory is allocated to processes, segment by segment, in non-contiguous areas of physical memory.

Each segment has its own address space.


\section*{Segment table}

\subsection*{Definition}

The \textbf{segment table} is responsible for mapping logical program addresses to physical memory addresses when using segmentation.


\subsection*{Mapping logical program addresses to physical memory addresses}

Each logical address is formed as \texttt{(s,d)} where
\begin{itemize}
	\item \texttt{s} is the segment reference; and
	\item \texttt{d} is the displacement within that segment (offset).
\end{itemize}
\texttt{s} occupies 4 bits and while \texttt{d} occupies 12 bits.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/segmentation-logical-program-address.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Logical program address in segmentation.}
  \end{minipage}}
\end{figure}

In addition, each process has a segment table, which records the base address and the length of the segment.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/logical-program-address-and-segment-table.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Logical program address and respective segment table.}
  \end{minipage}}
\end{figure}

The implementation is performed by the hardware, as such the Memory Management Unit (MMU) is responsible for mapping the logical addresses to physical addresses.

Given a 16-bit program address \texttt{0100 0001 0111 1010}, it can be deduced that:
\begin{equation*}
	\begin{aligned}
		\text{p} & = & 0100_{2} & = & 4_{10} \\
		\text{d} & = & 0001\;0111\;1010_{2} & = & 378_{10}
	\end{aligned}
\end{equation*}

The segment reference (\texttt{s}) provides an index to a location in the segment table.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/using-s-as-index-to-segment-table.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Using \texttt{s} as an index to the segment table.}
  \end{minipage}}
\end{figure}

A check is also performed to ensure that the displacement value (\texttt{d}) is less than the segment length recorded in the segment table.

If the check is passed, the sum of the value of the base address (\texttt{b}) at index \texttt{4} in the segment table and the displacement value (\texttt{d}) from the logical program address can then be used as the physical memory address.

\begin{figure}[H]
  \lineskip=-\fboxrule
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \centering
    \includegraphics[max size={\textwidth}{5cm}]{images/chapter-6/segmentation-logical-program-address-to-physical-memory-address.png}
  \end{minipage}}
  \fbox{\begin{minipage}{\dimexpr \textwidth-2\fboxsep-2\fboxrule}
    \abovecaptionskip=0pt
    \caption{Using the value at index \texttt{4} as the base (\texttt{b}).}
  \end{minipage}}
\end{figure}

This can also be shown by performing the following operations:
\begin{equation*}
	\begin{aligned}
		\text{physical memory address} & = \text{base address (b)} + \text{displacement value (d)} \\
		\text{physical memory address} & = 0101\;0010\;0111\;1011 + 001\;0111\;1010 \\
		\text{physical memory address} & = 0101\;0011\;1111\;0101_{2} = 21493_{10}
	\end{aligned}
\end{equation*}


\section*{Protection and sharing}

Segmentation aids protection as it:
\begin{itemize}
	\item assigns different modes, such as read, write and execute, to each segment; and
	\item checks that memory references do not exceed the segment length, therefore preventing a process accessing another process' segments.
\end{itemize}

Segmentation aids sharing as a shared segment can be referenced by multiple processes, such as libraries.


\section*{Evaluation of segmentation}

\begin{longtabu} to \textwidth {| X[1,l] | X[1,l] |}
    \hline
    \textbf{Advantages} & \textbf{Disadvantages}
	\\ \hline
	\textbf{Support the logical divisions of programs} as segments are based on the program's attributes. &
	\textbf{Wasted space} as segments are usually much larger than pages.
	\\ \hline
	\textbf{Segments can grow and shrink} dynamically and independently, such as the stack and heap. &
	\textbf{External fragmentation}.
	\\ \hline
	\textbf{Aids sharing and protection}. &
	\\ \hline
\end{longtabu}


\section{Comparison of paging and segmentation}

\begin{longtabu} to \textwidth {| X[0.6,l] | X[1,l] | X[1,l] |}
    \hline
    \textbf{Attribute} & \textbf{Paging} & \textbf{Segmentation}
	\\ \hline
	\textbf{Uses} &
	Useful to have more address space without having to purchase more physical memory. &
	Useful to allow programs to be broken up in to independent logical address spaces.
	\\ \hline
	\textbf{Memory division} &
	Physical division of memory which is transparent to the user. &
	Logical division of memory which is visible to the user.
	\\ \hline
	\textbf{Size} &
	Fixed size as each page is a pre-determined fixed size. &
	Variable size as segments can be dynamic, such as stack and heap.
	\\ \hline
	\textbf{Fragmentation} &
	No external fragmentation. &
	Generates memory holes.
	\\ \hline
	\textbf{Address space} &
	\multicolumn{2}{|l|}{The total address space can exceed the size of physical memory.}
	\\ \hline
\end{longtabu}


\section{Paging segments}

\textbf{Paging segments} is a method of combining paging and segmentation by assigning each segment with a page table. 

Segments are typically larger than pages and, in the case where a segment does not fit in physical memory, this method must be used.

This allows the advantages of both memory management schemes to be present, such that this method:
\begin{itemize}
	\item avoids external fragmentation;
	\item aids sharing and protection; and
	\item supports the user-view of programs.
\end{itemize}

Paging segments is roughly the method used in modern systems, such as Intel-based systems.

\end{document}
